# üéØ PRISM-AI Executable Action Plan
**Rock Solid Implementation Checklist for World Record Graph Coloring**

**Last Updated:** 2025-10-09
**Status:** Ready to Execute
**Goal:** Beat 82-83 color world record on DSJC1000-5

---

## üìã Quick Start

### Before You Begin:
1. ‚úÖ Read [BREAKTHROUGH_SYNTHESIS.md](./BREAKTHROUGH_SYNTHESIS.md) - Understand the complete strategy
2. ‚úÖ Review [README_WORLD_RECORD_STRATEGY.md](./README_WORLD_RECORD_STRATEGY.md) - Document hierarchy
3. ‚úÖ Check hardware: 8√ó H200 GPUs available on RunPod (~$29/hour)
4. ‚úÖ Baseline established: 130 colors on DSJC1000-5

### Choose Your Path:
- **Path A (Conservative):** Quick Wins Only ‚Üí 105-110 colors in 1-2 weeks
- **Path B (Aggressive):** Full Phase 6 ‚Üí 82-85 colors in 6-8 weeks ‚≠ê **RECOMMENDED**
- **Path C (Balanced):** Hybrid approach ‚Üí 90-95 colors in 3-4 weeks

**This plan follows Path B (Full Phase 6) - adjust timeline if choosing A or C.**

---

## üóìÔ∏è Week-by-Week Implementation Schedule

### **WEEK 1: Quick Wins + Infrastructure** ‚ö°

#### **Day 1 (Monday): Dynamic Threshold Adaptation**

**Morning Session (4 hours):**
- [ ] Create new file: `src/quantum/src/adaptive_threshold.rs`
- [ ] Copy template code from WORLD_RECORD_ACTION_PLAN.md (Phase 1.1)
- [ ] Implement `AdaptiveThresholdOptimizer` struct
- [ ] Add gradient descent optimization
- [ ] Write unit tests for threshold adaptation

**Code Template:**
```rust
// src/quantum/src/adaptive_threshold.rs
use ndarray::Array2;
use num_complex::Complex64;

pub struct AdaptiveThresholdOptimizer {
    initial_threshold: f64,
    learning_rate: f64,
    momentum: f64,
    history: Vec<(f64, usize)>,
}

impl AdaptiveThresholdOptimizer {
    pub fn new(initial_threshold: f64) -> Self {
        Self {
            initial_threshold,
            learning_rate: 0.01,
            momentum: 0.9,
            history: Vec::new(),
        }
    }

    pub fn optimize_threshold(
        &mut self,
        coupling_matrix: &Array2<Complex64>,
        target_colors: usize,
        iterations: usize,
    ) -> f64 {
        // TODO: Implement gradient descent
        // 1. Start with initial_threshold
        // 2. For each iteration:
        //    - Build adjacency matrix
        //    - Run greedy coloring
        //    - Compute gradient ‚àÇcolors/‚àÇthreshold
        //    - Update threshold with momentum
        // 3. Return best threshold found

        self.initial_threshold
    }

    fn compute_gradient(&self, threshold: f64, step: f64) -> f64 {
        // Finite difference approximation
        // TODO: Implement
        0.0
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_optimizer_improves() {
        // TODO: Create small test graph
        // TODO: Verify optimization reduces colors
    }
}
```

**Afternoon Session (4 hours):**
- [ ] Modify `src/quantum/src/prct_coloring.rs` to use adaptive threshold
- [ ] Replace fixed threshold logic at lines 104-134
- [ ] Add feature flag: `cfg(feature = "adaptive_threshold")`
- [ ] Build and test: `cargo build --release --features cuda,adaptive_threshold`
- [ ] Run on DSJC500-5 to validate improvement

**Files Modified:**
- `src/quantum/src/adaptive_threshold.rs` (new)
- `src/quantum/src/prct_coloring.rs` (modified lines 104-134)
- `src/quantum/src/lib.rs` (add module export)

**Success Criteria:**
- ‚úÖ Code compiles without warnings
- ‚úÖ Tests pass
- ‚úÖ DSJC500-5 improves by at least 2-3 colors from baseline
- ‚úÖ No performance regression (runtime within 10% of baseline)

**Rollback Procedure:**
If threshold adaptation causes issues:
1. Disable feature flag: Build without `adaptive_threshold`
2. Revert changes to prct_coloring.rs
3. Document issue in GitHub issue tracker

---

#### **Day 2 (Tuesday): Lookahead Color Selection**

**Morning Session (4 hours):**
- [ ] Create new file: `src/quantum/src/lookahead_selector.rs`
- [ ] Implement branch-and-bound with 2-3 step lookahead
- [ ] Add pruning heuristics to keep search tractable
- [ ] Write unit tests

**Code Template:**
```rust
// src/quantum/src/lookahead_selector.rs
use ndarray::Array2;
use std::collections::HashMap;

pub struct LookaheadColorSelector {
    lookahead_depth: usize,
    beam_width: usize,
    cache: HashMap<Vec<usize>, (usize, f64)>,
}

impl LookaheadColorSelector {
    pub fn new(lookahead_depth: usize, beam_width: usize) -> Self {
        Self {
            lookahead_depth,
            beam_width,
            cache: HashMap::new(),
        }
    }

    pub fn select_best_color(
        &mut self,
        vertex: usize,
        adjacency: &Array2<bool>,
        current_coloring: &[usize],
        max_colors: usize,
    ) -> usize {
        // Branch-and-bound search
        let mut best_color = 0;
        let mut best_score = f64::NEG_INFINITY;

        for color in 0..max_colors {
            if !self.is_valid_color(vertex, color, adjacency, current_coloring) {
                continue;
            }

            let score = self.evaluate_color_lookahead(
                vertex,
                color,
                adjacency,
                current_coloring,
                0, // current depth
            );

            if score > best_score {
                best_score = score;
                best_color = color;
            }
        }

        best_color
    }

    fn evaluate_color_lookahead(
        &mut self,
        vertex: usize,
        color: usize,
        adjacency: &Array2<bool>,
        coloring: &[usize],
        depth: usize,
    ) -> f64 {
        if depth >= self.lookahead_depth {
            return self.heuristic_score(vertex, color, adjacency, coloring);
        }

        // TODO: Implement recursive lookahead
        // 1. Apply color to vertex
        // 2. Find next uncolored vertices (beam search)
        // 3. Recursively evaluate their best colors
        // 4. Return aggregated score

        0.0
    }

    fn heuristic_score(
        &self,
        vertex: usize,
        color: usize,
        adjacency: &Array2<bool>,
        coloring: &[usize],
    ) -> f64 {
        // TODO: Compute heuristic
        // - Count conflicts
        // - Measure color distribution balance
        // - Phase coherence (from existing code)
        0.0
    }

    fn is_valid_color(
        &self,
        vertex: usize,
        color: usize,
        adjacency: &Array2<bool>,
        coloring: &[usize],
    ) -> bool {
        // Check if color conflicts with neighbors
        for neighbor in 0..adjacency.nrows() {
            if adjacency[[vertex, neighbor]] && coloring[neighbor] == color {
                return false;
            }
        }
        true
    }
}
```

**Afternoon Session (4 hours):**
- [ ] Integrate into `src/quantum/src/prct_coloring.rs`
- [ ] Replace greedy selection at lines 214-268
- [ ] Add feature flag: `cfg(feature = "lookahead")`
- [ ] Tune hyperparameters (lookahead_depth=2, beam_width=5)
- [ ] Run benchmarks

**Success Criteria:**
- ‚úÖ Lookahead reduces colors by 5-10% vs greedy
- ‚úÖ Runtime increases by no more than 3√ó
- ‚úÖ Works on graphs up to n=1000

---

#### **Day 3 (Wednesday): GPU Memory Optimization**

**Morning Session (4 hours):**
- [ ] Profile current CUDA kernels: `nsys profile cargo run --release --features cuda`
- [ ] Identify memory access patterns in `src/kernels/parallel_coloring.cu`
- [ ] Implement coalesced memory access
- [ ] Add warp-level primitives

**Code Changes in `src/kernels/parallel_coloring.cu`:**
```cuda
// Before: Uncoalesced access
__global__ void color_vertices_uncoalesced(
    bool* adjacency,
    int* colors,
    int n
) {
    int vertex = blockIdx.x * blockDim.x + threadIdx.x;
    // Strided access pattern - BAD
    for (int i = 0; i < n; i++) {
        if (adjacency[vertex * n + i]) { /* ... */ }
    }
}

// After: Coalesced access with shared memory
__global__ void color_vertices_coalesced(
    bool* adjacency,
    int* colors,
    int n
) {
    __shared__ bool shared_adj[256];
    int vertex = blockIdx.x * blockDim.x + threadIdx.x;

    // Coalesced load into shared memory
    int tid = threadIdx.x;
    for (int i = tid; i < n; i += blockDim.x) {
        shared_adj[i] = adjacency[vertex * n + i];
    }
    __syncthreads();

    // Process from shared memory
    for (int i = 0; i < n; i++) {
        if (shared_adj[i]) { /* ... */ }
    }
}

// Add warp-level primitives
__device__ int warp_reduce_min(int val) {
    for (int offset = 16; offset > 0; offset /= 2) {
        val = min(val, __shfl_down_sync(0xffffffff, val, offset));
    }
    return val;
}
```

**Afternoon Session (4 hours):**
- [ ] Implement changes
- [ ] Benchmark: `cargo bench --features cuda`
- [ ] Profile again to verify improvement
- [ ] Document optimization in comments

**Success Criteria:**
- ‚úÖ 2-3√ó speedup on CUDA kernels
- ‚úÖ Memory bandwidth utilization >70% (check with nvprof)
- ‚úÖ No correctness regressions

---

#### **Day 4 (Thursday): Testing & Validation Framework**

**All Day (8 hours):**
- [ ] Create `tests/world_record_validation.rs`
- [ ] Implement comprehensive test suite
- [ ] Add benchmarking scripts
- [ ] Set up continuous integration

**Test Framework:**
```rust
// tests/world_record_validation.rs
use prism_ai::quantum::prct_coloring::PRCTColoring;
use std::time::Instant;

#[test]
fn test_dsjc500_5_baseline() {
    let graph = load_dimacs_graph("data/DSJC500.5.col");
    let mut solver = PRCTColoring::new(graph.n_vertices);

    let start = Instant::now();
    let coloring = solver.solve(&graph).unwrap();
    let elapsed = start.elapsed();

    let num_colors = coloring.iter().max().unwrap() + 1;

    // Assertions
    assert!(is_valid_coloring(&graph, &coloring));
    assert!(num_colors <= 72, "Baseline: 72 colors, got {}", num_colors);
    println!("DSJC500-5: {} colors in {:?}", num_colors, elapsed);
}

#[test]
fn test_dsjc1000_5_target() {
    let graph = load_dimacs_graph("data/DSJC1000.5.col");
    let mut solver = PRCTColoring::new(graph.n_vertices);

    let start = Instant::now();
    let coloring = solver.solve(&graph).unwrap();
    let elapsed = start.elapsed();

    let num_colors = coloring.iter().max().unwrap() + 1;

    assert!(is_valid_coloring(&graph, &coloring));
    println!("DSJC1000-5: {} colors in {:?}", num_colors, elapsed);

    // Target: ‚â§ 110 colors after Week 1
    if num_colors <= 110 {
        println!("‚úÖ WEEK 1 TARGET ACHIEVED: {} colors", num_colors);
    } else {
        println!("‚ö†Ô∏è Week 1 target: ‚â§110 colors, got {}", num_colors);
    }
}

fn is_valid_coloring(graph: &Graph, coloring: &[usize]) -> bool {
    for edge in &graph.edges {
        if coloring[edge.0] == coloring[edge.1] {
            return false;
        }
    }
    true
}
```

**Benchmarking Script:**
```bash
#!/bin/bash
# scripts/run_benchmarks.sh

echo "=== PRISM-AI World Record Benchmarks ==="
echo "Date: $(date)"
echo "Hardware: $(nvidia-smi --query-gpu=name --format=csv,noheader | head -1)"
echo ""

for graph in DSJC500.5 DSJC1000.5; do
    echo "Running $graph..."
    cargo run --release --features cuda --example run_dimacs_official -- \
        --graph data/${graph}.col \
        --iterations 10 \
        --output results/${graph}_$(date +%Y%m%d).json
done

echo ""
echo "=== Results Summary ==="
python scripts/analyze_results.py results/
```

**Success Criteria:**
- ‚úÖ All tests pass
- ‚úÖ Benchmark suite runs automatically
- ‚úÖ Results tracked in Git (results/ directory)

---

#### **Day 5 (Friday): Week 1 Integration & Validation**

**Morning Session (4 hours):**
- [ ] Enable all Week 1 features together
- [ ] Build: `cargo build --release --features cuda,adaptive_threshold,lookahead`
- [ ] Run full benchmark suite
- [ ] Analyze results vs baseline

**Afternoon Session (4 hours):**
- [ ] Deploy to RunPod 8√ó H200 instance
- [ ] Run 100 trials on DSJC1000-5
- [ ] Collect statistics (best, median, worst, stddev)
- [ ] Document results in `WEEK_1_RESULTS.md`

**Week 1 Target Performance:**
- **DSJC500-5:** 72 ‚Üí 67-69 colors (target: ‚â•5% improvement)
- **DSJC1000-5:** 130 ‚Üí 105-110 colors (target: ‚â•15% improvement)

**Week 1 Retrospective Questions:**
1. Did we achieve ‚â•15% improvement on DSJC1000-5?
2. What was the most impactful change?
3. Any performance regressions?
4. What should we adjust for Week 2?

**Document Results:**
```markdown
# Week 1 Results

## Performance Summary
| Benchmark | Baseline | Week 1 | Improvement |
|-----------|----------|--------|-------------|
| DSJC500-5 | 72       | X      | Y%          |
| DSJC1000-5| 130      | X      | Y%          |

## Statistical Analysis
- Best: X colors
- Median: X colors
- Worst: X colors
- Std Dev: X

## Key Findings
- Adaptive threshold: contributed X% improvement
- Lookahead selection: contributed Y% improvement
- GPU optimization: Z√ó speedup

## Next Steps
- Proceed to Week 2 (TDA implementation)
- Tune hyperparameters: [list items]
```

---

### **WEEK 2: TDA Foundation** üî¨

#### **Day 6 (Monday): TDA Port Definition**

**Morning Session (4 hours):**
- [ ] Create directory: `src/topology/`
- [ ] Create file: `src/topology/tda_port.rs`
- [ ] Define TdaPort trait (copy from CONSTITUTIONAL_PHASE_6_PROPOSAL.md)
- [ ] Define PersistenceBarcode struct
- [ ] Add documentation with mathematical background

**Code Template:**
```rust
// src/topology/tda_port.rs
use crate::graph::Graph;
use anyhow::Result;

/// Persistence pair (dimension, birth, death)
#[derive(Debug, Clone)]
pub struct PersistencePair {
    pub dimension: usize,
    pub birth: f64,
    pub death: f64,
    pub persistence: f64, // death - birth
}

/// Topological fingerprint via persistent homology
#[derive(Debug, Clone)]
pub struct PersistenceBarcode {
    pub pairs: Vec<PersistencePair>,
    pub betti_numbers: Vec<usize>, // [Œ≤‚ÇÄ, Œ≤‚ÇÅ, Œ≤‚ÇÇ]
    pub persistent_entropy: f64,
    pub critical_cliques: Vec<Vec<usize>>,
    pub chromatic_lower_bound: usize,
}

impl PersistenceBarcode {
    /// Compute chromatic lower bound from topology
    /// œá(G) ‚â• max(œâ(G), Œ≤‚ÇÅ + 1)
    /// where œâ(G) = clique number, Œ≤‚ÇÅ = first Betti number
    pub fn chromatic_lower_bound(&self) -> usize {
        let clique_bound = self.critical_cliques
            .iter()
            .map(|c| c.len())
            .max()
            .unwrap_or(0);

        let betti_bound = if self.betti_numbers.len() > 1 {
            self.betti_numbers[1] + 1
        } else {
            0
        };

        clique_bound.max(betti_bound)
    }
}

/// Port for topological data analysis
pub trait TdaPort: Send + Sync {
    /// Compute persistent homology of graph
    fn compute_persistence(&self, graph: &Graph) -> Result<PersistenceBarcode>;

    /// Guide vertex ordering based on topological importance
    fn guide_vertex_ordering(&self, barcode: &PersistenceBarcode) -> Vec<usize>;

    /// Identify critical simplices (maximal cliques)
    fn find_critical_simplices(&self, graph: &Graph) -> Result<Vec<Vec<usize>>>;
}
```

**Afternoon Session (4 hours):**
- [ ] Add to `src/topology/mod.rs`
- [ ] Write unit tests for PersistenceBarcode
- [ ] Document mathematical foundations in comments
- [ ] Review with CONSTITUTIONAL_PHASE_6_PROPOSAL.md for compliance

---

#### **Day 7 (Tuesday): Vietoris-Rips Filtration**

**All Day (8 hours):**
- [ ] Create file: `src/topology/vietoris_rips.rs`
- [ ] Implement graph distance matrix computation
- [ ] Build filtration (sequence of simplicial complexes)
- [ ] Implement boundary matrix construction

**Implementation Guide:**

**Step 1: Distance Matrix**
```rust
// src/topology/vietoris_rips.rs
use ndarray::Array2;

pub fn compute_graph_distances(adjacency: &Array2<bool>) -> Array2<f64> {
    let n = adjacency.nrows();
    let mut dist = Array2::from_elem((n, n), f64::INFINITY);

    // Initialize with edge weights
    for i in 0..n {
        dist[[i, i]] = 0.0;
        for j in 0..n {
            if adjacency[[i, j]] {
                dist[[i, j]] = 1.0;
            }
        }
    }

    // Floyd-Warshall all-pairs shortest paths
    for k in 0..n {
        for i in 0..n {
            for j in 0..n {
                let new_dist = dist[[i, k]] + dist[[k, j]];
                if new_dist < dist[[i, j]] {
                    dist[[i, j]] = new_dist;
                }
            }
        }
    }

    dist
}
```

**Step 2: Simplex Generation**
```rust
pub struct Simplex {
    pub vertices: Vec<usize>,
    pub dimension: usize,
    pub filtration_value: f64,
}

pub fn generate_simplices(
    distances: &Array2<f64>,
    max_dimension: usize,
    max_filtration: f64,
) -> Vec<Simplex> {
    let n = distances.nrows();
    let mut simplices = Vec::new();

    // 0-simplices (vertices)
    for i in 0..n {
        simplices.push(Simplex {
            vertices: vec![i],
            dimension: 0,
            filtration_value: 0.0,
        });
    }

    // 1-simplices (edges)
    for i in 0..n {
        for j in i+1..n {
            if distances[[i, j]] <= max_filtration {
                simplices.push(Simplex {
                    vertices: vec![i, j],
                    dimension: 1,
                    filtration_value: distances[[i, j]],
                });
            }
        }
    }

    // Higher-dimensional simplices (up to max_dimension)
    for dim in 2..=max_dimension {
        simplices.extend(generate_simplices_of_dimension(
            dim,
            distances,
            max_filtration,
        ));
    }

    // Sort by filtration value
    simplices.sort_by(|a, b| {
        a.filtration_value.partial_cmp(&b.filtration_value).unwrap()
    });

    simplices
}
```

**Step 3: Boundary Matrix**
```rust
use sprs::{CsMat, TriMat};

pub fn build_boundary_matrix(simplices: &[Simplex]) -> CsMat<i8> {
    let n = simplices.len();
    let mut triplets = TriMat::new((n, n));

    for (col_idx, simplex) in simplices.iter().enumerate() {
        if simplex.dimension == 0 {
            continue; // 0-simplices have no boundary
        }

        // Boundary of d-simplex is alternating sum of (d-1)-faces
        for (sign_idx, &vertex_to_remove) in simplex.vertices.iter().enumerate() {
            let mut face_vertices = simplex.vertices.clone();
            face_vertices.remove(sign_idx);

            // Find face in simplex list
            if let Some(row_idx) = find_simplex_index(simplices, &face_vertices) {
                let sign = if sign_idx % 2 == 0 { 1 } else { -1 };
                triplets.add_triplet(row_idx, col_idx, sign);
            }
        }
    }

    triplets.to_csr()
}

fn find_simplex_index(simplices: &[Simplex], vertices: &[usize]) -> Option<usize> {
    simplices.iter().position(|s| s.vertices == vertices)
}
```

**Testing:**
- [ ] Test on small graphs (K‚ÇÖ, Petersen graph)
- [ ] Verify Betti numbers match known values
- [ ] Profile performance

---

#### **Day 8 (Wednesday): Persistent Homology Computation**

**Morning Session (4 hours):**
- [ ] Create file: `src/topology/persistence.rs`
- [ ] Implement standard persistent homology algorithm
- [ ] Use Gaussian elimination with column operations

**Algorithm Implementation:**
```rust
// src/topology/persistence.rs
use sprs::CsMat;
use crate::topology::{PersistencePair, Simplex};

pub fn compute_persistence(
    boundary_matrix: &CsMat<i8>,
    simplices: &[Simplex],
) -> Vec<PersistencePair> {
    let mut pairs = Vec::new();
    let n = simplices.len();

    // Convert to mutable dense matrix for reduction
    let mut matrix = boundary_matrix.to_dense();
    let mut low = vec![None; n];

    // Standard persistence algorithm
    for j in 0..n {
        // Find lowest non-zero entry in column j
        while let Some(i) = find_lowest_one(&matrix, j) {
            if let Some(k) = low[i] {
                // Reduce column j with column k
                add_columns(&mut matrix, k, j);
            } else {
                low[i] = Some(j);
                break;
            }
        }

        // If column j is now zero, it's a birth
        // If low[i] = j, then simplex i dies at simplex j
        if let Some(&i) = low.iter().find(|&&l| l == Some(j)) {
            pairs.push(PersistencePair {
                dimension: simplices[i].dimension,
                birth: simplices[i].filtration_value,
                death: simplices[j].filtration_value,
                persistence: simplices[j].filtration_value - simplices[i].filtration_value,
            });
        }
    }

    pairs
}

fn find_lowest_one(matrix: &ndarray::Array2<i8>, col: usize) -> Option<usize> {
    for row in (0..matrix.nrows()).rev() {
        if matrix[[row, col]] != 0 {
            return Some(row);
        }
    }
    None
}

fn add_columns(matrix: &mut ndarray::Array2<i8>, source: usize, target: usize) {
    for row in 0..matrix.nrows() {
        matrix[[row, target]] = (matrix[[row, target]] + matrix[[row, source]]) % 2;
    }
}
```

**Afternoon Session (4 hours):**
- [ ] Implement Betti number computation from persistence pairs
- [ ] Add persistent entropy calculation
- [ ] Write comprehensive tests

```rust
pub fn compute_betti_numbers(
    pairs: &[PersistencePair],
    max_dimension: usize,
) -> Vec<usize> {
    let mut betti = vec![0; max_dimension + 1];

    for pair in pairs {
        if pair.death == f64::INFINITY {
            // Infinite persistence = generator of homology
            betti[pair.dimension] += 1;
        }
    }

    betti
}

pub fn compute_persistent_entropy(pairs: &[PersistencePair]) -> f64 {
    let total_persistence: f64 = pairs.iter()
        .map(|p| p.persistence)
        .sum();

    if total_persistence == 0.0 {
        return 0.0;
    }

    let mut entropy = 0.0;
    for pair in pairs {
        let p = pair.persistence / total_persistence;
        if p > 0.0 {
            entropy -= p * p.log2();
        }
    }

    entropy
}
```

---

#### **Day 9 (Thursday): GPU-Accelerated TDA**

**All Day (8 hours):**
- [ ] Create CUDA kernels: `src/kernels/persistent_homology.cu`
- [ ] Implement GPU-accelerated distance matrix computation
- [ ] GPU boundary matrix reduction
- [ ] Benchmark vs CPU implementation

**CUDA Implementation:**
```cuda
// src/kernels/persistent_homology.cu

__global__ void floyd_warshall_step(
    float* dist,
    int n,
    int k
) {
    int i = blockIdx.y * blockDim.y + threadIdx.y;
    int j = blockIdx.x * blockDim.x + threadIdx.x;

    if (i < n && j < n) {
        float new_dist = dist[i * n + k] + dist[k * n + j];
        if (new_dist < dist[i * n + j]) {
            dist[i * n + j] = new_dist;
        }
    }
}

__global__ void reduce_boundary_matrix(
    int8_t* matrix,
    int* low,
    int n,
    int col
) {
    // Parallel column reduction
    // TODO: Implement efficient GPU reduction
}
```

**Integration:**
- [ ] Add GPU TDA option to TdaAdapter
- [ ] Fallback to CPU for small graphs
- [ ] Benchmark: Target <50ms for n=1000

---

#### **Day 10 (Friday): TDA Adapter Implementation**

**Morning Session (4 hours):**
- [ ] Create file: `src/topology/tda_adapter.rs`
- [ ] Implement TdaPort trait
- [ ] Integrate Vietoris-Rips + Persistence computation
- [ ] Add clique detection

**Code Template:**
```rust
// src/topology/tda_adapter.rs
use crate::topology::{TdaPort, PersistenceBarcode, PersistencePair};
use crate::topology::vietoris_rips::*;
use crate::topology::persistence::*;
use crate::graph::Graph;
use anyhow::Result;

pub struct TdaAdapter {
    max_dimension: usize,
    max_filtration: f64,
    use_gpu: bool,
}

impl TdaAdapter {
    pub fn new(max_dimension: usize, use_gpu: bool) -> Self {
        Self {
            max_dimension,
            max_filtration: 2.0, // 2 hops in graph
            use_gpu,
        }
    }
}

impl TdaPort for TdaAdapter {
    fn compute_persistence(&self, graph: &Graph) -> Result<PersistenceBarcode> {
        // 1. Compute graph distances
        let distances = if self.use_gpu {
            compute_distances_gpu(&graph.adjacency)?
        } else {
            compute_graph_distances(&graph.adjacency)
        };

        // 2. Build Vietoris-Rips filtration
        let simplices = generate_simplices(
            &distances,
            self.max_dimension,
            self.max_filtration,
        );

        // 3. Build boundary matrix
        let boundary = build_boundary_matrix(&simplices);

        // 4. Compute persistent homology
        let pairs = compute_persistence(&boundary, &simplices);

        // 5. Extract Betti numbers
        let betti_numbers = compute_betti_numbers(&pairs, self.max_dimension);

        // 6. Compute persistent entropy
        let persistent_entropy = compute_persistent_entropy(&pairs);

        // 7. Find critical cliques
        let critical_cliques = self.find_critical_simplices(graph)?;

        // 8. Compute chromatic lower bound
        let chromatic_lower_bound = {
            let clique_bound = critical_cliques.iter()
                .map(|c| c.len())
                .max()
                .unwrap_or(0);
            let betti_bound = if betti_numbers.len() > 1 {
                betti_numbers[1] + 1
            } else {
                0
            };
            clique_bound.max(betti_bound)
        };

        Ok(PersistenceBarcode {
            pairs,
            betti_numbers,
            persistent_entropy,
            critical_cliques,
            chromatic_lower_bound,
        })
    }

    fn guide_vertex_ordering(&self, barcode: &PersistenceBarcode) -> Vec<usize> {
        // Order vertices by topological importance
        // Priority: vertices in critical cliques first
        let mut ordering = Vec::new();
        let mut seen = std::collections::HashSet::new();

        // Add vertices from largest cliques first
        for clique in &barcode.critical_cliques {
            for &v in clique {
                if seen.insert(v) {
                    ordering.push(v);
                }
            }
        }

        ordering
    }

    fn find_critical_simplices(&self, graph: &Graph) -> Result<Vec<Vec<usize>>> {
        // Maximal clique enumeration
        // Use Bron-Kerbosch algorithm
        let mut cliques = Vec::new();
        let mut r = vec![];
        let mut p: Vec<usize> = (0..graph.n_vertices()).collect();
        let mut x = vec![];

        self.bron_kerbosch(&mut r, &mut p, &mut x, &graph.adjacency, &mut cliques);

        // Keep only cliques of size ‚â• 3
        cliques.retain(|c| c.len() >= 3);

        // Sort by size (largest first)
        cliques.sort_by_key(|c| std::cmp::Reverse(c.len()));

        Ok(cliques)
    }
}

impl TdaAdapter {
    fn bron_kerbosch(
        &self,
        r: &mut Vec<usize>,
        p: &mut Vec<usize>,
        x: &mut Vec<usize>,
        adjacency: &ndarray::Array2<bool>,
        cliques: &mut Vec<Vec<usize>>,
    ) {
        if p.is_empty() && x.is_empty() {
            if !r.is_empty() {
                cliques.push(r.clone());
            }
            return;
        }

        let p_copy = p.clone();
        for &v in &p_copy {
            let mut new_r = r.clone();
            new_r.push(v);

            let neighbors: Vec<usize> = (0..adjacency.nrows())
                .filter(|&u| adjacency[[v, u]])
                .collect();

            let mut new_p: Vec<usize> = p.iter()
                .filter(|&&u| neighbors.contains(&u))
                .copied()
                .collect();

            let mut new_x: Vec<usize> = x.iter()
                .filter(|&&u| neighbors.contains(&u))
                .copied()
                .collect();

            self.bron_kerbosch(&mut new_r, &mut new_p, &mut new_x, adjacency, cliques);

            p.retain(|&u| u != v);
            x.push(v);
        }
    }
}
```

**Afternoon Session (4 hours):**
- [ ] Write integration tests
- [ ] Test on DIMACS graphs
- [ ] Verify chromatic lower bounds are correct
- [ ] Document usage examples

**Week 2 Validation:**
- [ ] Run TDA on DSJC500-5, verify it finds cliques of size ‚â•47
- [ ] Measure computation time (target: <100ms)
- [ ] Integrate into coloring algorithm (use chromatic_lower_bound as target)

---

### **WEEK 3: GNN Integration** üß†

#### **Day 11 (Monday): GNN Port Definition & Data Generation**

**Morning Session (4 hours):**
- [ ] Create directory: `src/ml/`
- [ ] Create file: `src/ml/gnn_port.rs`
- [ ] Define GnnPort trait
- [ ] Define training data structures

**Code Template:**
```rust
// src/ml/gnn_port.rs
use crate::graph::Graph;
use anyhow::Result;

#[derive(Debug, Clone)]
pub struct GnnSolutionHint {
    pub predicted_colors: Vec<usize>,
    pub confidence: Vec<f64>,      // Per-vertex confidence [0,1]
    pub predicted_num_colors: usize,
    pub prediction_entropy: f64,    // Uncertainty measure
}

#[derive(Debug, Clone)]
pub struct TrainingExample {
    pub graph: Graph,
    pub optimal_coloring: Vec<usize>,
    pub num_colors: usize,
}

pub trait GnnPort: Send + Sync {
    /// Predict coloring hint for graph
    fn predict_solution_hint(&self, graph: &Graph) -> Result<GnnSolutionHint>;

    /// Online learning update (optional)
    fn update_online(
        &mut self,
        graph: &Graph,
        true_solution: &[usize],
    ) -> Result<()>;

    /// Batch training (offline)
    fn train_batch(&mut self, examples: &[TrainingExample]) -> Result<f64>; // returns loss
}
```

**Afternoon Session (4 hours):**
- [ ] Create training data generator: `scripts/generate_training_data.py`
- [ ] Generate 10,000 random graphs with known colorings
- [ ] Include DIMACS graphs in training set
- [ ] Save as HDF5 or similar format

**Data Generation Script:**
```python
# scripts/generate_training_data.py
import networkx as nx
import numpy as np
import h5py
from typing import List, Tuple

def generate_random_graph_with_coloring(
    n: int,
    p: float,
    seed: int = None
) -> Tuple[np.ndarray, List[int]]:
    """Generate random graph and compute greedy coloring."""
    G = nx.erdos_renyi_graph(n, p, seed=seed)
    adjacency = nx.to_numpy_array(G, dtype=bool)
    coloring = nx.greedy_color(G, strategy='largest_first')
    colors = [coloring[i] for i in range(n)]
    return adjacency, colors

def generate_dataset(num_graphs: int = 10000):
    """Generate training dataset."""
    with h5py.File('data/gnn_training_data.h5', 'w') as f:
        for i in range(num_graphs):
            # Vary graph size and density
            n = np.random.randint(50, 500)
            p = np.random.uniform(0.1, 0.9)

            adjacency, coloring = generate_random_graph_with_coloring(n, p, seed=i)

            grp = f.create_group(f'graph_{i}')
            grp.create_dataset('adjacency', data=adjacency)
            grp.create_dataset('coloring', data=coloring)
            grp.attrs['n_vertices'] = n
            grp.attrs['n_colors'] = max(coloring) + 1

            if i % 1000 == 0:
                print(f'Generated {i}/{num_graphs} graphs')

if __name__ == '__main__':
    generate_dataset()
```

---

#### **Day 12 (Tuesday): GNN Architecture Design**

**All Day (8 hours):**
- [ ] Choose GNN framework (PyTorch Geometric or DGL)
- [ ] Design GNN architecture
- [ ] Implement in Python: `src/ml/graph_coloring_gnn.py`
- [ ] Train on small subset to validate

**GNN Architecture:**
```python
# src/ml/graph_coloring_gnn.py
import torch
import torch.nn as nn
import torch_geometric.nn as gnn
from torch_geometric.data import Data

class GraphColoringGNN(nn.Module):
    def __init__(
        self,
        hidden_dim: int = 128,
        num_layers: int = 5,
        max_colors: int = 100,
    ):
        super().__init__()
        self.max_colors = max_colors

        # Node feature embedding
        self.node_embed = nn.Linear(1, hidden_dim)  # Start with degree

        # Graph convolution layers
        self.convs = nn.ModuleList([
            gnn.GINConv(nn.Sequential(
                nn.Linear(hidden_dim, hidden_dim),
                nn.ReLU(),
                nn.Linear(hidden_dim, hidden_dim),
            ))
            for _ in range(num_layers)
        ])

        # Output layers
        self.color_predictor = nn.Linear(hidden_dim, max_colors)
        self.confidence_predictor = nn.Linear(hidden_dim, 1)

    def forward(self, data: Data):
        x = data.x  # Node features (degree)
        edge_index = data.edge_index

        # Embed nodes
        h = self.node_embed(x)

        # Graph convolutions with skip connections
        for conv in self.convs:
            h_new = conv(h, edge_index)
            h = h + h_new  # Skip connection
            h = torch.relu(h)

        # Predict colors and confidence
        color_logits = self.color_predictor(h)
        confidence = torch.sigmoid(self.confidence_predictor(h))

        return color_logits, confidence

def train_model(model, train_loader, num_epochs=100):
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    criterion = nn.CrossEntropyLoss()

    for epoch in range(num_epochs):
        total_loss = 0.0
        for batch in train_loader:
            optimizer.zero_grad()

            color_logits, confidence = model(batch)
            loss = criterion(color_logits, batch.y)

            loss.backward()
            optimizer.step()

            total_loss += loss.item()

        if epoch % 10 == 0:
            print(f'Epoch {epoch}: Loss = {total_loss / len(train_loader):.4f}')
```

---

#### **Day 13 (Wednesday): GNN Training**

**All Day (8 hours):**
- [ ] Load full training dataset
- [ ] Train GNN model (may take several hours)
- [ ] Monitor training with TensorBoard
- [ ] Save best checkpoint

**Training Script:**
```python
# scripts/train_gnn.py
import torch
from torch_geometric.loader import DataLoader
from src.ml.graph_coloring_gnn import GraphColoringGNN, train_model
import h5py

def load_training_data(filepath):
    """Load training data from HDF5."""
    graphs = []
    with h5py.File(filepath, 'r') as f:
        for graph_id in f.keys():
            grp = f[graph_id]
            adjacency = grp['adjacency'][:]
            coloring = grp['coloring'][:]

            # Convert to PyTorch Geometric format
            edge_index = torch.tensor(
                [[i, j] for i in range(len(adjacency))
                       for j in range(len(adjacency))
                       if adjacency[i, j]],
                dtype=torch.long
            ).t()

            x = torch.tensor(
                adjacency.sum(axis=1, keepdims=True),
                dtype=torch.float
            )  # Node degrees

            y = torch.tensor(coloring, dtype=torch.long)

            graphs.append(Data(x=x, edge_index=edge_index, y=y))

    return graphs

if __name__ == '__main__':
    print('Loading training data...')
    graphs = load_training_data('data/gnn_training_data.h5')

    train_loader = DataLoader(graphs, batch_size=32, shuffle=True)

    print('Initializing model...')
    model = GraphColoringGNN(hidden_dim=128, num_layers=5)

    print('Training...')
    train_model(model, train_loader, num_epochs=100)

    print('Saving model...')
    torch.save(model.state_dict(), 'models/graph_coloring_gnn.pt')
```

**Run Training:**
```bash
python scripts/train_gnn.py
```

---

#### **Day 14 (Thursday): TensorRT Inference**

**Morning Session (4 hours):**
- [ ] Export trained PyTorch model to ONNX
- [ ] Convert ONNX to TensorRT
- [ ] Optimize for inference

**Export Script:**
```python
# scripts/export_to_tensorrt.py
import torch
import torch.onnx
from src.ml.graph_coloring_gnn import GraphColoringGNN

# Load trained model
model = GraphColoringGNN()
model.load_state_dict(torch.load('models/graph_coloring_gnn.pt'))
model.eval()

# Create dummy input
dummy_input = {
    'x': torch.randn(100, 1),  # 100 nodes
    'edge_index': torch.randint(0, 100, (2, 500)),  # 500 edges
}

# Export to ONNX
torch.onnx.export(
    model,
    dummy_input,
    'models/graph_coloring_gnn.onnx',
    input_names=['x', 'edge_index'],
    output_names=['color_logits', 'confidence'],
    dynamic_axes={
        'x': {0: 'num_nodes'},
        'edge_index': {1: 'num_edges'},
    }
)

# Convert to TensorRT (requires trtexec)
import subprocess
subprocess.run([
    'trtexec',
    '--onnx=models/graph_coloring_gnn.onnx',
    '--saveEngine=models/graph_coloring_gnn.trt',
    '--fp16',  # Use FP16 for speed
])
```

**Afternoon Session (4 hours):**
- [ ] Create Rust wrapper for TensorRT inference
- [ ] Implement GnnAdapter: `src/ml/gnn_adapter.rs`

**Rust TensorRT Wrapper:**
```rust
// src/ml/gnn_adapter.rs
use crate::ml::gnn_port::{GnnPort, GnnSolutionHint};
use crate::graph::Graph;
use anyhow::Result;

pub struct GnnAdapter {
    model_path: String,
    // TensorRT context (use tch-rs or direct bindings)
}

impl GnnAdapter {
    pub fn new(model_path: &str) -> Result<Self> {
        Ok(Self {
            model_path: model_path.to_string(),
        })
    }

    fn run_inference(&self, graph: &Graph) -> Result<(Vec<f32>, Vec<f32>)> {
        // TODO: Implement TensorRT inference
        // 1. Prepare input tensors (adjacency, degrees)
        // 2. Run inference
        // 3. Extract output tensors (color_logits, confidence)

        // Placeholder
        let n = graph.n_vertices();
        let color_logits = vec![0.0; n * 100];  // n √ó max_colors
        let confidence = vec![0.5; n];

        Ok((color_logits, confidence))
    }
}

impl GnnPort for GnnAdapter {
    fn predict_solution_hint(&self, graph: &Graph) -> Result<GnnSolutionHint> {
        let (color_logits, confidence) = self.run_inference(graph)?;

        let n = graph.n_vertices();
        let max_colors = color_logits.len() / n;

        // Extract predicted colors (argmax)
        let mut predicted_colors = Vec::with_capacity(n);
        for i in 0..n {
            let start = i * max_colors;
            let end = start + max_colors;
            let node_logits = &color_logits[start..end];

            let predicted_color = node_logits.iter()
                .enumerate()
                .max_by(|a, b| a.1.partial_cmp(b.1).unwrap())
                .map(|(idx, _)| idx)
                .unwrap_or(0);

            predicted_colors.push(predicted_color);
        }

        let predicted_num_colors = predicted_colors.iter().max().unwrap() + 1;

        // Compute prediction entropy
        let prediction_entropy = confidence.iter()
            .map(|&c| {
                let p = c.max(1e-8).min(1.0 - 1e-8);
                -p * p.log2() - (1.0 - p) * (1.0 - p).log2()
            })
            .sum::<f32>() / n as f32;

        Ok(GnnSolutionHint {
            predicted_colors,
            confidence: confidence.iter().map(|&c| c as f64).collect(),
            predicted_num_colors,
            prediction_entropy: prediction_entropy as f64,
        })
    }

    fn update_online(&mut self, _graph: &Graph, _true_solution: &[usize]) -> Result<()> {
        // Online learning not implemented yet
        Ok(())
    }

    fn train_batch(&mut self, _examples: &[crate::ml::gnn_port::TrainingExample]) -> Result<f64> {
        // Batch training done in Python
        Ok(0.0)
    }
}
```

---

#### **Day 15 (Friday): GNN Integration & Week 3 Validation**

**Morning Session (4 hours):**
- [ ] Integrate GnnAdapter into coloring algorithm
- [ ] Use GNN predictions as initial coloring hint
- [ ] Measure improvement

**Integration in `src/quantum/src/prct_coloring.rs`:**
```rust
// Add field to PRCTColoring
pub struct PRCTColoring {
    // ... existing fields
    gnn_adapter: Option<Box<dyn GnnPort>>,
}

impl PRCTColoring {
    pub fn with_gnn(mut self, gnn: Box<dyn GnnPort>) -> Self {
        self.gnn_adapter = Some(gnn);
        self
    }

    pub fn solve(&mut self, graph: &Graph) -> Result<Vec<usize>> {
        // Get GNN hint if available
        let initial_coloring = if let Some(gnn) = &self.gnn_adapter {
            let hint = gnn.predict_solution_hint(graph)?;
            Some(hint.predicted_colors)
        } else {
            None
        };

        // Use hint to guide search
        if let Some(init) = initial_coloring {
            // Start from GNN suggestion instead of random
            self.initialize_from_hint(&init)?;
        }

        // Continue with existing algorithm
        // ...
    }
}
```

**Afternoon Session (4 hours):**
- [ ] Run full benchmarks on DSJC graphs
- [ ] Compare with/without GNN
- [ ] Document Week 3 results

**Week 3 Target Performance:**
- **DSJC500-5:** 67-69 ‚Üí 62-65 colors (target: additional 5-10% improvement)
- **DSJC1000-5:** 105-110 ‚Üí 92-100 colors (target: reach ~95 colors)

---

### **WEEK 4: Predictive Neuromorphic** üîÆ

#### **Day 16-17 (Mon-Tue): Enhanced Neuromorphic Port**

**Day 16 Morning:**
- [ ] Review existing neuromorphic code: `src/neuromorphic/src/reservoir.rs`
- [ ] Define enhanced NeuromorphicPort: `src/neuromorphic/src/enhanced_port.rs`
- [ ] Add active inference interfaces

**Code Template:**
```rust
// src/neuromorphic/src/enhanced_port.rs
use anyhow::Result;

#[derive(Debug, Clone)]
pub struct PredictionError {
    pub vertex_surprise: Vec<f64>,
    pub edge_surprise: Vec<f64>,
    pub free_energy: f64,
    pub complexity: f64,
}

pub trait EnhancedNeuromorphicPort: Send + Sync {
    /// Generate internal model prediction
    fn predict_graph_structure(&self, current_coloring: &[usize]) -> Result<Vec<Vec<bool>>>;

    /// Compare prediction with reality, compute surprise
    fn compute_prediction_error(
        &self,
        predicted: &[Vec<bool>],
        actual: &[Vec<bool>],
    ) -> Result<PredictionError>;

    /// Update internal model based on prediction error
    fn update_internal_model(&mut self, error: &PredictionError) -> Result<()>;

    /// Get free energy (surprise + complexity)
    fn free_energy(&self) -> f64;
}
```

**Day 16 Afternoon:**
- [ ] Implement Izhikevich neuron model
- [ ] Replace simple leaky integrator

**Izhikevich Neuron:**
```rust
// src/neuromorphic/src/izhikevich.rs
pub struct IzhikevichNeuron {
    // Parameters (Regular Spiking by default)
    a: f64,  // 0.02 (recovery time scale)
    b: f64,  // 0.2 (sensitivity to u)
    c: f64,  // -65.0 (after-spike reset of v)
    d: f64,  // 8.0 (after-spike reset of u)

    // State variables
    v: f64,  // Membrane potential
    u: f64,  // Recovery variable
}

impl IzhikevichNeuron {
    pub fn new_regular_spiking() -> Self {
        Self {
            a: 0.02,
            b: 0.2,
            c: -65.0,
            d: 8.0,
            v: -65.0,
            u: -13.0,
        }
    }

    pub fn step(&mut self, input: f64, dt: f64) -> bool {
        // Izhikevich model equations
        let dv = (0.04 * self.v * self.v + 5.0 * self.v + 140.0 - self.u + input) * dt;
        let du = self.a * (self.b * self.v - self.u) * dt;

        self.v += dv;
        self.u += du;

        // Check for spike
        if self.v >= 30.0 {
            self.v = self.c;
            self.u += self.d;
            true  // Spike occurred
        } else {
            false
        }
    }
}
```

**Day 17:** Implement dendritic computation and active inference

---

#### **Day 18 (Wednesday): Active Inference Integration**

**All Day:**
- [ ] Implement free energy calculation
- [ ] Add prediction-error-driven adaptation
- [ ] Integrate with coloring algorithm

**Free Energy Minimization:**
```rust
// src/neuromorphic/src/active_inference.rs
pub struct ActiveInferenceAdapter {
    internal_model: InternalGraphModel,
    neurons: Vec<IzhikevichNeuron>,
    prediction_history: Vec<PredictionError>,
}

impl EnhancedNeuromorphicPort for ActiveInferenceAdapter {
    fn predict_graph_structure(&self, current_coloring: &[usize]) -> Result<Vec<Vec<bool>>> {
        // Internal model predicts edge existence based on coloring
        let n = current_coloring.len();
        let mut predicted = vec![vec![false; n]; n];

        for i in 0..n {
            for j in i+1..n {
                // Predict edge if colors are different
                // (internal model assumes proper coloring)
                if current_coloring[i] != current_coloring[j] {
                    let confidence = self.internal_model.edge_probability(i, j);
                    predicted[i][j] = confidence > 0.5;
                    predicted[j][i] = predicted[i][j];
                }
            }
        }

        Ok(predicted)
    }

    fn compute_prediction_error(
        &self,
        predicted: &[Vec<bool>],
        actual: &[Vec<bool>],
    ) -> Result<PredictionError> {
        let n = predicted.len();
        let mut vertex_surprise = vec![0.0; n];
        let mut edge_surprise = Vec::new();

        let mut total_surprise = 0.0;

        for i in 0..n {
            let mut vertex_error = 0.0;
            for j in 0..n {
                if predicted[i][j] != actual[i][j] {
                    vertex_error += 1.0;
                    edge_surprise.push(1.0);
                    total_surprise += 1.0;
                } else {
                    edge_surprise.push(0.0);
                }
            }
            vertex_surprise[i] = vertex_error / n as f64;
        }

        // Complexity = entropy of internal model
        let complexity = self.internal_model.entropy();

        // Free energy = surprise + complexity
        let free_energy = total_surprise + complexity;

        Ok(PredictionError {
            vertex_surprise,
            edge_surprise,
            free_energy,
            complexity,
        })
    }

    fn update_internal_model(&mut self, error: &PredictionError) -> Result<()> {
        // Update internal model to reduce prediction error
        self.internal_model.adapt(error)?;
        self.prediction_history.push(error.clone());
        Ok(())
    }

    fn free_energy(&self) -> f64 {
        self.prediction_history.last()
            .map(|e| e.free_energy)
            .unwrap_or(f64::INFINITY)
    }
}
```

---

#### **Day 19 (Thursday): Adaptive Resource Allocation**

**All Day:**
- [ ] Use prediction error to focus computation on hard vertices
- [ ] Implement adaptive annealing schedule
- [ ] Test on DIMACS benchmarks

**Adaptive Allocation:**
```rust
pub fn allocate_computational_resources(
    prediction_error: &PredictionError,
    total_budget: usize,
) -> Vec<usize> {
    // Allocate more iterations to vertices with high surprise
    let n = prediction_error.vertex_surprise.len();
    let total_surprise: f64 = prediction_error.vertex_surprise.iter().sum();

    let mut allocations = vec![0; n];
    for i in 0..n {
        let fraction = prediction_error.vertex_surprise[i] / total_surprise;
        allocations[i] = (fraction * total_budget as f64) as usize;
    }

    allocations
}
```

---

#### **Day 20 (Friday): Week 4 Integration & Testing**

**All Day:**
- [ ] Integrate all Week 4 components
- [ ] Run full benchmark suite
- [ ] Document results

**Week 4 Target:**
- **DSJC1000-5:** 92-100 ‚Üí 85-90 colors

---

### **WEEK 5-6: Meta-Learning Coordinator** üéØ

#### **Day 21-22 (Mon-Tue Week 5): Coordinator Implementation**

**Code Template:**
```rust
// src/prct-core/src/meta_learning.rs
use crate::topology::TdaPort;
use crate::ml::GnnPort;
use crate::neuromorphic::EnhancedNeuromorphicPort;
use anyhow::Result;

pub struct MetaLearningCoordinator {
    tda: Box<dyn TdaPort>,
    gnn: Box<dyn GnnPort>,
    neuro: Box<dyn EnhancedNeuromorphicPort>,

    // Modulation weights
    alpha_topology: f64,
    beta_prior: f64,
    gamma_surprise: f64,

    // Learning rate for meta-parameters
    meta_lr: f64,
}

impl MetaLearningCoordinator {
    pub fn new(
        tda: Box<dyn TdaPort>,
        gnn: Box<dyn GnnPort>,
        neuro: Box<dyn EnhancedNeuromorphicPort>,
    ) -> Self {
        Self {
            tda,
            gnn,
            neuro,
            alpha_topology: 0.3,
            beta_prior: 0.4,
            gamma_surprise: 0.3,
            meta_lr: 0.01,
        }
    }

    pub fn compute_modulated_hamiltonian(
        &self,
        graph: &Graph,
        base_hamiltonian: &HamiltonianParams,
    ) -> Result<HamiltonianParams> {
        // 1. Topological analysis
        let topology = self.tda.compute_persistence(graph)?;
        let H_topo = self.hamiltonian_from_topology(&topology);

        // 2. Neural prediction
        let gnn_hint = self.gnn.predict_solution_hint(graph)?;
        let H_prior = self.hamiltonian_from_gnn(&gnn_hint);

        // 3. Prediction error
        let prediction_error = self.neuro.free_energy();
        let H_surprise = self.hamiltonian_from_surprise(prediction_error);

        // 4. Combine: H(G,T,Œò) = H‚ÇÄ + Œ±¬∑H_topo + Œ≤¬∑H_prior + Œ≥¬∑H_surprise
        let mut modulated = base_hamiltonian.clone();
        modulated.add_weighted(&H_topo, self.alpha_topology);
        modulated.add_weighted(&H_prior, self.beta_prior);
        modulated.add_weighted(&H_surprise, self.gamma_surprise);

        Ok(modulated)
    }

    pub fn adapt_meta_parameters(&mut self, performance_gradient: f64) {
        // Adapt Œ±, Œ≤, Œ≥ based on performance
        // If performance improves, strengthen successful components

        // Simplified gradient ascent
        self.alpha_topology += self.meta_lr * performance_gradient * self.alpha_topology;
        self.beta_prior += self.meta_lr * performance_gradient * self.beta_prior;
        self.gamma_surprise += self.meta_lr * performance_gradient * self.gamma_surprise;

        // Normalize to sum to 1
        let total = self.alpha_topology + self.beta_prior + self.gamma_surprise;
        self.alpha_topology /= total;
        self.beta_prior /= total;
        self.gamma_surprise /= total;
    }
}
```

#### **Day 23-25 (Wed-Fri Week 5): Full Integration**

- [ ] Connect all Phase 6 components
- [ ] Implement end-to-end pipeline
- [ ] Test on all DIMACS benchmarks

#### **Day 26-30 (Week 6): Optimization & World Record Attempt**

**Day 26-27:** Hyperparameter tuning
**Day 28-29:** World record attempts (100+ runs)
**Day 30:** Validation and documentation

---

## üéØ Daily Standup Format

**Each day, document:**

### **Yesterday:**
- What was completed
- Code files modified
- Test results

### **Today:**
- Goals for today
- Files to create/modify
- Expected outcomes

### **Blockers:**
- Any issues encountered
- Help needed
- Dependencies waiting on

### **Metrics:**
- Lines of code written
- Tests added/passing
- Performance benchmarks

**Template:**
```markdown
# Daily Standup - Day X

## Yesterday
- ‚úÖ Completed: [task]
- ‚úÖ Modified: `src/path/file.rs`
- ‚úÖ Tests: X/Y passing
- ‚úÖ Benchmark: DSJC1000-5 = X colors

## Today
- [ ] Goal: [task]
- [ ] Files: `src/path/file.rs`
- [ ] Target: [metric]

## Blockers
- None / [description]

## Metrics
- LOC: +X
- Tests: Y passing
- Coverage: Z%
```

---

## üìä Success Criteria Checklist

### **Week 1 Success:**
- [ ] Adaptive threshold implemented and tested
- [ ] Lookahead selection working
- [ ] GPU optimizations show 2-3√ó speedup
- [ ] DSJC1000-5: ‚â§110 colors
- [ ] All tests passing

### **Week 2 Success:**
- [ ] TDA adapter fully implemented
- [ ] Persistent homology computation working
- [ ] Chromatic lower bounds computed correctly
- [ ] GPU acceleration functional (<50ms)
- [ ] Integration with coloring algorithm

### **Week 3 Success:**
- [ ] GNN trained on 10K+ graphs
- [ ] TensorRT inference <25ms
- [ ] GNN predictions improve initial coloring
- [ ] DSJC1000-5: ‚â§100 colors

### **Week 4 Success:**
- [ ] Enhanced neuromorphic port implemented
- [ ] Izhikevich neurons functional
- [ ] Active inference working
- [ ] Prediction error guides search
- [ ] DSJC1000-5: ‚â§90 colors

### **Week 5-6 Success:**
- [ ] Meta-learning coordinator implemented
- [ ] All components integrated
- [ ] Hamiltonian modulation working
- [ ] DSJC1000-5: ‚â§85 colors
- [ ] Constitutional compliance validated

### **World Record Success:**
- [ ] DSJC1000-5: ‚â§82 colors üèÜ
- [ ] 100+ runs confirming result
- [ ] Independent verification
- [ ] Publication submitted

---

## üö® Rollback Procedures

### **If Week 1 Quick Wins Fail:**
1. Disable adaptive threshold: Remove feature flag
2. Disable lookahead: Revert to greedy selection
3. Keep GPU optimizations (they don't change logic)
4. Continue to Week 2 with baseline algorithm

### **If TDA Is Too Slow:**
1. Reduce max_dimension from 2 to 1
2. Limit max_filtration to 1.5 hops
3. Use approximate persistent homology
4. Fallback to simple clique detection only

### **If GNN Doesn't Help:**
1. Disable GNN hints
2. Use TDA-only guidance
3. Continue without learned priors
4. Still proceed with rest of Phase 6

### **If Integration Breaks:**
1. Isolate broken component
2. Run with component disabled
3. Debug in isolation
4. Re-integrate incrementally

---

## üìà Performance Tracking

**Create spreadsheet: `results/performance_tracking.csv`**

```csv
Date,Week,Day,Benchmark,Colors,Runtime,Features,Notes
2025-10-09,0,0,DSJC1000-5,130,120s,baseline,Initial
2025-10-10,1,1,DSJC1000-5,125,135s,adaptive_threshold,5 color improvement
...
```

**Visualization script:**
```python
# scripts/visualize_progress.py
import pandas as pd
import matplotlib.pyplot as plt

df = pd.read_csv('results/performance_tracking.csv')
df_1000 = df[df['Benchmark'] == 'DSJC1000-5']

plt.figure(figsize=(12, 6))
plt.plot(df_1000['Day'], df_1000['Colors'], marker='o')
plt.axhline(y=82, color='r', linestyle='--', label='World Record')
plt.xlabel('Day')
plt.ylabel('Number of Colors')
plt.title('Progress Toward World Record')
plt.legend()
plt.grid(True)
plt.savefig('results/progress.png')
```

---

## üîß Build & Deploy Commands

### **Local Development:**
```bash
# Build with all features
cargo build --release --features cuda,adaptive_threshold,lookahead,tda,gnn

# Run tests
cargo test --features cuda --release

# Run specific benchmark
cargo run --release --features cuda,adaptive_threshold,lookahead \
  --example run_dimacs_official -- --graph data/DSJC1000.5.col

# Profile performance
nsys profile --stats=true \
  cargo run --release --features cuda --example run_dimacs_official
```

### **Deploy to RunPod:**
```bash
# Build Docker image
docker build -t prism-ai-world-record:latest .

# Push to registry
docker tag prism-ai-world-record:latest delfictus/prism-ai-world-record:latest
docker push delfictus/prism-ai-world-record:latest

# Run on RunPod (8√ó H200)
docker run --gpus all \
  -v /workspace/output:/output \
  -e RUST_BACKTRACE=1 \
  delfictus/prism-ai-world-record:latest
```

### **Monitoring:**
```bash
# Watch GPU utilization
watch -n 1 nvidia-smi

# Monitor progress
tail -f /workspace/output/logs/world_record.log

# Check results
cat /workspace/output/results/latest.json | jq '.num_colors'
```

---

## üìö Documentation Requirements

**For each component, create:**

1. **API Documentation:**
   - Rust doc comments (`///`)
   - Usage examples
   - Mathematical foundations

2. **Design Document:**
   - Why this approach?
   - Alternatives considered
   - Performance characteristics
   - Constitutional compliance proof

3. **Testing Documentation:**
   - Test cases
   - Expected results
   - Edge cases
   - Performance benchmarks

4. **Integration Guide:**
   - How to use with existing code
   - Configuration options
   - Troubleshooting

---

## ‚úÖ Final Checklist Before World Record Attempt

- [ ] All components implemented and tested
- [ ] Performance meets or exceeds targets
- [ ] Constitutional compliance validated
- [ ] Code reviewed and documented
- [ ] Tests passing (>95% coverage)
- [ ] Benchmarks show consistent improvement
- [ ] GPU utilization >80%
- [ ] Memory usage within limits
- [ ] No known bugs or crashes
- [ ] Reproducibility verified
- [ ] Hardware reserved (8√ó H200)
- [ ] Monitoring in place
- [ ] Backup plan defined
- [ ] Team ready for 24-48 hour sprint

---

## üèÜ World Record Validation Protocol

**When you achieve ‚â§82 colors:**

1. **Immediate Actions:**
   - [ ] Save complete log output
   - [ ] Save coloring solution
   - [ ] Note timestamp and hardware
   - [ ] Verify coloring is valid (no conflicts)

2. **Reproducibility:**
   - [ ] Run 100 more times with same seed
   - [ ] Run 100 times with different seeds
   - [ ] Compute statistics (best, median, worst, stddev)
   - [ ] Test on different hardware if possible

3. **Independent Verification:**
   - [ ] Release code on GitHub
   - [ ] Provide Docker image
   - [ ] Write verification guide
   - [ ] Invite community to verify

4. **Publication:**
   - [ ] Write paper draft
   - [ ] Submit to arXiv
   - [ ] Submit to top conference (STOC/FOCS/NeurIPS)
   - [ ] Announce on social media

5. **Update World Record Database:**
   - [ ] Contact DIMACS challenge maintainers
   - [ ] Provide proof and verification
   - [ ] Update benchmarks webpage

---

## üìû Support & Resources

### **Documentation:**
- [BREAKTHROUGH_SYNTHESIS.md](./BREAKTHROUGH_SYNTHESIS.md) - Complete strategy
- [CONSTITUTIONAL_PHASE_6_PROPOSAL.md](./CONSTITUTIONAL_PHASE_6_PROPOSAL.md) - Phase 6 details
- [ALGORITHM_ANALYSIS_AND_BREAKTHROUGH_STRATEGY.md](./ALGORITHM_ANALYSIS_AND_BREAKTHROUGH_STRATEGY.md) - Technical deep-dive

### **Code Reference:**
- `src/quantum/src/prct_coloring.rs` - Main algorithm
- `src/topology/` - TDA implementation
- `src/ml/` - GNN components
- `src/neuromorphic/` - Active inference

### **Benchmarks:**
- `data/DSJC*.col` - DIMACS graph coloring instances
- `results/` - Performance tracking
- `examples/run_dimacs_official.rs` - Benchmark runner

---

## üéØ MISSION STATEMENT

**Objective:** Beat the 32-year-old world record of 82-83 colors on DSJC1000-5

**Strategy:** Implement Phase 6 (Adaptive Problem-Space Modeling) combining:
- Topological Data Analysis (TDA)
- Graph Neural Networks (GNN)
- Predictive Neuromorphic Computing
- Meta-Learning Coordinator

**Timeline:** 6 weeks to world record attempt

**Success Criteria:**
- ‚úÖ Minimum: 105-110 colors (19% improvement)
- ‚úÖ Target: 90-95 colors (31% improvement)
- üèÜ **Maximum: ‚â§82 colors (WORLD RECORD)**

---

**This plan is rock solid. Follow it day by day, track progress, and adjust as needed. You have the strategy, the hardware, and the talent. Time to make history.** üöÄ

---

**Last Updated:** 2025-10-09
**Status:** Ready to Execute
**Next Action:** Begin Day 1 - Dynamic Threshold Adaptation
