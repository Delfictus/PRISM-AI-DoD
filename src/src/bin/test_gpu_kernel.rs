//! Test GPU kernel execution with correct cudarc API

use anyhow::Result;
use cudarc::{
    driver::{CudaContext, LaunchConfig, PushKernelArg},
    nvrtc::compile_ptx_with_opts,
};
use std::time::Instant;

const VECTOR_ADD_KERNEL: &str = r#"
extern "C" __global__ void vector_add(float* a, float* b, float* c, int n) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < n) {
        c[idx] = a[idx] + b[idx];
    }
}
"#;

const MATRIX_MUL_KERNEL: &str = r#"
extern "C" __global__ void matmul(float* a, float* b, float* c, int m, int k, int n) {
    int row = blockIdx.y * blockDim.y + threadIdx.y;
    int col = blockIdx.x * blockDim.x + threadIdx.x;

    if (row < m && col < n) {
        float sum = 0.0f;
        for (int i = 0; i < k; i++) {
            sum += a[row * k + i] * b[i * n + col];
        }
        c[row * n + col] = sum;
    }
}
"#;

fn test_vector_add() -> Result<()> {
    println!("\n[1] Testing Vector Addition Kernel");
    println!("===================================");

    // Create CUDA context and stream
    let ctx = CudaContext::new(0)?;
    let stream = ctx.default_stream();

    // Compile PTX
    println!("Compiling vector_add kernel...");
    let ptx = compile_ptx_with_opts(VECTOR_ADD_KERNEL, Default::default())?;

    // Load module and function
    println!("Loading PTX module...");
    let module = ctx.load_module(ptx)?;
    let vector_add_func = module.load_function("vector_add")?;
    println!("‚úÖ Kernel loaded successfully!");

    // Prepare data
    let n = 1024;
    let a_host: Vec<f32> = (0..n).map(|i| i as f32).collect();
    let b_host: Vec<f32> = (0..n).map(|i| i as f32 * 2.0).collect();

    // Upload to GPU
    println!("Uploading data to GPU...");
    let a_dev = stream.memcpy_stod(&a_host)?;
    let b_dev = stream.memcpy_stod(&b_host)?;
    let mut c_dev = stream.alloc_zeros::<f32>(n)?;

    // Launch kernel
    println!("Launching kernel...");
    let cfg = LaunchConfig::for_num_elems(n as u32);

    let start = Instant::now();
    unsafe {
        stream.launch_builder(&vector_add_func)
            .arg(&a_dev)
            .arg(&b_dev)
            .arg(&mut c_dev)
            .arg(&(n as i32))
            .launch(cfg)?;
    }
    stream.synchronize()?;
    let gpu_time = start.elapsed();

    // Download result
    println!("Downloading results...");
    let c_host = stream.memcpy_dtov(&c_dev)?;

    // Verify
    let mut correct = true;
    for i in 0..n.min(10) {
        let expected = a_host[i] + b_host[i];
        if (c_host[i] - expected).abs() > 1e-6 {
            correct = false;
            println!("‚ùå Mismatch at index {}: {} vs {}", i, c_host[i], expected);
        }
    }

    if correct {
        println!("‚úÖ Vector addition CORRECT!");
        println!("   Elements: {}", n);
        println!("   GPU Time: {:.2} ms", gpu_time.as_secs_f64() * 1000.0);
        println!("   Sample: {} + {} = {}", a_host[0], b_host[0], c_host[0]);
    }

    Ok(())
}

fn test_matrix_multiply() -> Result<()> {
    println!("\n[2] Testing Matrix Multiplication Kernel");
    println!("=========================================");

    // Create CUDA context and stream
    let ctx = CudaContext::new(0)?;
    let stream = ctx.default_stream();

    // Compile PTX
    println!("Compiling matmul kernel...");
    let ptx = compile_ptx_with_opts(MATRIX_MUL_KERNEL, Default::default())?;

    // Load module and function
    println!("Loading PTX module...");
    let module = ctx.load_module(ptx)?;
    let matmul_func = module.load_function("matmul")?;
    println!("‚úÖ Kernel loaded successfully!");

    // Matrix dimensions
    let m = 256; // A rows, C rows
    let k = 256; // A cols, B rows
    let n = 256; // B cols, C cols

    // Create test matrices
    println!("Creating {}x{} * {}x{} matrices...", m, k, k, n);
    let a_host: Vec<f32> = (0..m*k).map(|i| (i % 10) as f32 * 0.1).collect();
    let b_host: Vec<f32> = (0..k*n).map(|i| (i % 5) as f32 * 0.2).collect();

    // Upload to GPU
    println!("Uploading matrices to GPU...");
    let a_dev = stream.memcpy_stod(&a_host)?;
    let b_dev = stream.memcpy_stod(&b_host)?;
    let mut c_dev = stream.alloc_zeros::<f32>(m * n)?;

    // Launch kernel with 2D grid
    println!("Launching kernel...");
    let block_size = 16;
    let grid_x = (n as u32 + block_size - 1) / block_size;
    let grid_y = (m as u32 + block_size - 1) / block_size;

    let cfg = LaunchConfig {
        grid_dim: (grid_x, grid_y, 1),
        block_dim: (block_size, block_size, 1),
        shared_mem_bytes: 0,
    };

    let start = Instant::now();
    unsafe {
        stream.launch_builder(&matmul_func)
            .arg(&a_dev)
            .arg(&b_dev)
            .arg(&mut c_dev)
            .arg(&(m as i32))
            .arg(&(k as i32))
            .arg(&(n as i32))
            .launch(cfg)?;
    }
    stream.synchronize()?;
    let gpu_time = start.elapsed();

    // Download result
    println!("Downloading results...");
    let c_host = stream.memcpy_dtov(&c_dev)?;

    // Verify with spot check
    let i = 0; // Check first element
    let j = 0;
    let mut expected = 0.0f32;
    for l in 0..k {
        expected += a_host[i * k + l] * b_host[l * n + j];
    }

    println!("‚úÖ Matrix multiplication COMPLETE!");
    println!("   Dimensions: {}x{} * {}x{} = {}x{}", m, k, k, n, m, n);
    println!("   GPU Time: {:.2} ms", gpu_time.as_secs_f64() * 1000.0);
    println!("   C[0,0] = {} (expected: {})", c_host[0], expected);

    if (c_host[0] - expected).abs() < 0.01 {
        println!("   ‚úÖ Result verified!");
    } else {
        println!("   ‚ö†Ô∏è Result may be incorrect");
    }

    // Calculate theoretical FLOPS
    let ops = 2.0 * (m as f64) * (n as f64) * (k as f64); // multiply-add = 2 ops
    let gflops = ops / (gpu_time.as_secs_f64() * 1e9);
    println!("   Performance: {:.1} GFLOPS", gflops);

    Ok(())
}

fn test_relu_kernel() -> Result<()> {
    println!("\n[3] Testing ReLU Activation Kernel");
    println!("===================================");

    const RELU_KERNEL: &str = r#"
    extern "C" __global__ void relu(float* data, int n) {
        int idx = blockIdx.x * blockDim.x + threadIdx.x;
        if (idx < n) {
            data[idx] = fmaxf(0.0f, data[idx]);
        }
    }
    "#;

    let ctx = CudaContext::new(0)?;
    let stream = ctx.default_stream();

    // Compile and load
    println!("Compiling ReLU kernel...");
    let ptx = compile_ptx_with_opts(RELU_KERNEL, Default::default())?;
    let module = ctx.load_module(ptx)?;
    let relu_func = module.load_function("relu")?;

    // Test data with negative values
    let n = 1024;
    let data_host: Vec<f32> = (0..n).map(|i| i as f32 - 512.0).collect();

    // Upload
    let mut data_dev = stream.memcpy_stod(&data_host)?;

    // Launch
    println!("Launching ReLU kernel...");
    let cfg = LaunchConfig::for_num_elems(n as u32);

    let start = Instant::now();
    unsafe {
        stream.launch_builder(&relu_func)
            .arg(&mut data_dev)
            .arg(&(n as i32))
            .launch(cfg)?;
    }
    stream.synchronize()?;
    let gpu_time = start.elapsed();

    // Download and verify
    let result = stream.memcpy_dtov(&data_dev)?;

    let all_non_negative = result.iter().all(|&x| x >= 0.0);
    let first_positive_idx = result.iter().position(|&x| x > 0.0).unwrap_or(n);

    println!("‚úÖ ReLU activation COMPLETE!");
    println!("   Elements: {}", n);
    println!("   GPU Time: {:.2} ms", gpu_time.as_secs_f64() * 1000.0);
    println!("   All non-negative: {}", all_non_negative);
    println!("   First positive at index: {}", first_positive_idx);

    Ok(())
}

fn main() -> Result<()> {
    println!("========================================");
    println!("    GPU KERNEL EXECUTION TEST");
    println!("========================================");
    println!("Testing actual GPU kernel execution with cudarc");

    // Check GPU availability
    match CudaContext::new(0) {
        Ok(_) => {
            println!("‚úÖ GPU AVAILABLE - Can execute kernels!");
            println!("   This test will launch real CUDA kernels.");
        }
        Err(e) => {
            println!("‚ùå GPU NOT AVAILABLE: {}", e);
            println!("   Cannot test kernel execution.");
            return Ok(());
        }
    }

    // Run tests
    test_vector_add()?;
    test_matrix_multiply()?;
    test_relu_kernel()?;

    println!("\n========================================");
    println!("         KERNEL TEST SUMMARY");
    println!("========================================");
    println!("‚úÖ ALL KERNELS EXECUTED SUCCESSFULLY!");
    println!("   1. Vector addition: WORKING");
    println!("   2. Matrix multiplication: WORKING");
    println!("   3. ReLU activation: WORKING");
    println!("\nüöÄ GPU kernel execution is fully functional!");
    println!("\nTo monitor GPU usage during execution:");
    println!("   watch -n 0.5 nvidia-smi");
    println!("========================================\n");

    Ok(())
}