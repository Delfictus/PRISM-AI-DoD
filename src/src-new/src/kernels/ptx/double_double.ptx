//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-35583870
// Cuda compilation tools, release 12.8, V12.8.93
// Based on NVVM 7.0.1
//

.version 8.7
.target sm_70
.address_size 64

	// .globl	_Z12dd_array_addP7dd_realPKS_S2_i
.extern .func  (.param .b32 func_retval0) vprintf
(
	.param .b64 vprintf_param_0,
	.param .b64 vprintf_param_1
)
;
.const .align 8 .f64 DD_EPS = 0d396FFFFFFFFFFFF9;
.const .align 8 .f64 DD_SPLIT_THRESH = 0d7E2FFFFFFFFFFFFF;
.global .align 1 .b8 $str[34] = {37, 115, 58, 32, 37, 46, 49, 55, 101, 32, 43, 32, 37, 46, 49, 55, 101, 32, 40, 116, 111, 116, 97, 108, 58, 32, 37, 46, 51, 50, 101, 41, 10};
.extern .shared .align 16 .b8 sdata[];
.global .align 1 .b8 $str$1[39] = {61, 61, 61, 32, 68, 111, 117, 98, 108, 101, 45, 68, 111, 117, 98, 108, 101, 32, 65, 114, 105, 116, 104, 109, 101, 116, 105, 99, 32, 84, 101, 115, 116, 32, 61, 61, 61, 10};
.global .align 1 .b8 $str$2[10] = {49, 47, 51, 32, 43, 32, 49, 47, 55};
.global .align 1 .b8 $str$3[7] = {207, 128, 32, 42, 32, 101};
.global .align 1 .b8 $str$4[33] = {40, 49, 43, 105, 41, 32, 42, 32, 40, 50, 45, 105, 41, 32, 61, 32, 37, 46, 49, 55, 101, 32, 43, 32, 37, 46, 49, 55, 101, 32, 105, 10};

.visible .entry _Z12dd_array_addP7dd_realPKS_S2_i(
	.param .u64 _Z12dd_array_addP7dd_realPKS_S2_i_param_0,
	.param .u64 _Z12dd_array_addP7dd_realPKS_S2_i_param_1,
	.param .u64 _Z12dd_array_addP7dd_realPKS_S2_i_param_2,
	.param .u32 _Z12dd_array_addP7dd_realPKS_S2_i_param_3
)
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<6>;
	.reg .f64 	%fd<19>;
	.reg .b64 	%rd<11>;


	ld.param.u64 	%rd1, [_Z12dd_array_addP7dd_realPKS_S2_i_param_0];
	ld.param.u64 	%rd2, [_Z12dd_array_addP7dd_realPKS_S2_i_param_1];
	ld.param.u64 	%rd3, [_Z12dd_array_addP7dd_realPKS_S2_i_param_2];
	ld.param.u32 	%r2, [_Z12dd_array_addP7dd_realPKS_S2_i_param_3];
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r4, %ctaid.x;
	mov.u32 	%r5, %tid.x;
	mad.lo.s32 	%r1, %r4, %r3, %r5;
	setp.ge.s32 	%p1, %r1, %r2;
	@%p1 bra 	$L__BB0_2;

	cvta.to.global.u64 	%rd4, %rd2;
	mul.wide.s32 	%rd5, %r1, 16;
	add.s64 	%rd6, %rd4, %rd5;
	cvta.to.global.u64 	%rd7, %rd3;
	add.s64 	%rd8, %rd7, %rd5;
	ld.global.nc.f64 	%fd1, [%rd8];
	ld.global.nc.f64 	%fd2, [%rd6];
	add.f64 	%fd3, %fd2, %fd1;
	sub.f64 	%fd4, %fd3, %fd2;
	sub.f64 	%fd5, %fd3, %fd4;
	sub.f64 	%fd6, %fd2, %fd5;
	sub.f64 	%fd7, %fd1, %fd4;
	add.f64 	%fd8, %fd7, %fd6;
	ld.global.nc.f64 	%fd9, [%rd8+8];
	ld.global.nc.f64 	%fd10, [%rd6+8];
	add.f64 	%fd11, %fd10, %fd9;
	add.f64 	%fd12, %fd3, %fd11;
	sub.f64 	%fd13, %fd12, %fd3;
	sub.f64 	%fd14, %fd11, %fd13;
	add.f64 	%fd15, %fd8, %fd14;
	add.f64 	%fd16, %fd12, %fd15;
	sub.f64 	%fd17, %fd16, %fd12;
	sub.f64 	%fd18, %fd15, %fd17;
	cvta.to.global.u64 	%rd9, %rd1;
	add.s64 	%rd10, %rd9, %rd5;
	st.global.f64 	[%rd10], %fd16;
	st.global.f64 	[%rd10+8], %fd18;

$L__BB0_2:
	ret;

}
	// .globl	_Z20dd_matrix_vector_mulP10dd_complexPKS_S2_i
.visible .entry _Z20dd_matrix_vector_mulP10dd_complexPKS_S2_i(
	.param .u64 _Z20dd_matrix_vector_mulP10dd_complexPKS_S2_i_param_0,
	.param .u64 _Z20dd_matrix_vector_mulP10dd_complexPKS_S2_i_param_1,
	.param .u64 _Z20dd_matrix_vector_mulP10dd_complexPKS_S2_i_param_2,
	.param .u32 _Z20dd_matrix_vector_mulP10dd_complexPKS_S2_i_param_3
)
{
	.reg .pred 	%p<4>;
	.reg .b32 	%r<15>;
	.reg .f64 	%fd<150>;
	.reg .b64 	%rd<19>;


	ld.param.u64 	%rd8, [_Z20dd_matrix_vector_mulP10dd_complexPKS_S2_i_param_1];
	ld.param.u64 	%rd9, [_Z20dd_matrix_vector_mulP10dd_complexPKS_S2_i_param_2];
	ld.param.u32 	%r4, [_Z20dd_matrix_vector_mulP10dd_complexPKS_S2_i_param_3];
	mov.u32 	%r5, %ntid.x;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %tid.x;
	mad.lo.s32 	%r1, %r6, %r5, %r7;
	setp.ge.s32 	%p1, %r1, %r4;
	@%p1 bra 	$L__BB1_5;

	setp.lt.s32 	%p2, %r4, 1;
	mov.f64 	%fd146, 0d0000000000000000;
	mov.f64 	%fd147, %fd146;
	mov.f64 	%fd148, %fd146;
	mov.f64 	%fd149, %fd146;
	@%p2 bra 	$L__BB1_4;

	mul.lo.s32 	%r9, %r4, %r1;
	cvta.to.global.u64 	%rd10, %rd8;
	mul.wide.s32 	%rd11, %r9, 32;
	add.s64 	%rd12, %rd10, %rd11;
	add.s64 	%rd18, %rd12, 16;
	cvta.to.global.u64 	%rd17, %rd9;
	mov.f64 	%fd146, 0d0000000000000000;
	mov.u32 	%r14, 0;

$L__BB1_3:
	ld.global.nc.f64 	%fd21, [%rd17];
	ld.global.nc.f64 	%fd22, [%rd18+-16];
	mul.f64 	%fd23, %fd22, %fd21;
	mul.f64 	%fd24, %fd22, 0d41A0000002000000;
	sub.f64 	%fd25, %fd24, %fd22;
	sub.f64 	%fd26, %fd24, %fd25;
	sub.f64 	%fd27, %fd22, %fd26;
	mul.f64 	%fd28, %fd21, 0d41A0000002000000;
	sub.f64 	%fd29, %fd28, %fd21;
	sub.f64 	%fd30, %fd28, %fd29;
	sub.f64 	%fd31, %fd21, %fd30;
	mul.f64 	%fd32, %fd26, %fd30;
	sub.f64 	%fd33, %fd32, %fd23;
	fma.rn.f64 	%fd34, %fd26, %fd31, %fd33;
	fma.rn.f64 	%fd35, %fd27, %fd30, %fd34;
	fma.rn.f64 	%fd36, %fd27, %fd31, %fd35;
	ld.global.nc.f64 	%fd37, [%rd17+8];
	fma.rn.f64 	%fd38, %fd22, %fd37, %fd36;
	ld.global.nc.f64 	%fd39, [%rd18+-8];
	fma.rn.f64 	%fd40, %fd39, %fd21, %fd38;
	add.f64 	%fd41, %fd23, %fd40;
	sub.f64 	%fd42, %fd41, %fd23;
	sub.f64 	%fd43, %fd40, %fd42;
	ld.global.nc.f64 	%fd44, [%rd17+16];
	ld.global.nc.f64 	%fd45, [%rd18];
	mul.f64 	%fd46, %fd45, %fd44;
	mul.f64 	%fd47, %fd45, 0d41A0000002000000;
	sub.f64 	%fd48, %fd47, %fd45;
	sub.f64 	%fd49, %fd47, %fd48;
	sub.f64 	%fd50, %fd45, %fd49;
	mul.f64 	%fd51, %fd44, 0d41A0000002000000;
	sub.f64 	%fd52, %fd51, %fd44;
	sub.f64 	%fd53, %fd51, %fd52;
	sub.f64 	%fd54, %fd44, %fd53;
	mul.f64 	%fd55, %fd49, %fd53;
	sub.f64 	%fd56, %fd55, %fd46;
	fma.rn.f64 	%fd57, %fd49, %fd54, %fd56;
	fma.rn.f64 	%fd58, %fd50, %fd53, %fd57;
	fma.rn.f64 	%fd59, %fd50, %fd54, %fd58;
	ld.global.nc.f64 	%fd60, [%rd17+24];
	fma.rn.f64 	%fd61, %fd45, %fd60, %fd59;
	ld.global.nc.f64 	%fd62, [%rd18+8];
	fma.rn.f64 	%fd63, %fd62, %fd44, %fd61;
	add.f64 	%fd64, %fd46, %fd63;
	sub.f64 	%fd65, %fd64, %fd46;
	sub.f64 	%fd66, %fd63, %fd65;
	mul.f64 	%fd67, %fd22, %fd44;
	mul.f64 	%fd68, %fd26, %fd53;
	sub.f64 	%fd69, %fd68, %fd67;
	fma.rn.f64 	%fd70, %fd26, %fd54, %fd69;
	fma.rn.f64 	%fd71, %fd27, %fd53, %fd70;
	fma.rn.f64 	%fd72, %fd27, %fd54, %fd71;
	fma.rn.f64 	%fd73, %fd22, %fd60, %fd72;
	fma.rn.f64 	%fd74, %fd39, %fd44, %fd73;
	add.f64 	%fd75, %fd67, %fd74;
	sub.f64 	%fd76, %fd75, %fd67;
	sub.f64 	%fd77, %fd74, %fd76;
	mul.f64 	%fd78, %fd45, %fd21;
	mul.f64 	%fd79, %fd49, %fd30;
	sub.f64 	%fd80, %fd79, %fd78;
	fma.rn.f64 	%fd81, %fd49, %fd31, %fd80;
	fma.rn.f64 	%fd82, %fd50, %fd30, %fd81;
	fma.rn.f64 	%fd83, %fd50, %fd31, %fd82;
	fma.rn.f64 	%fd84, %fd45, %fd37, %fd83;
	fma.rn.f64 	%fd85, %fd62, %fd21, %fd84;
	add.f64 	%fd86, %fd78, %fd85;
	sub.f64 	%fd87, %fd86, %fd78;
	sub.f64 	%fd88, %fd85, %fd87;
	neg.f64 	%fd89, %fd64;
	sub.f64 	%fd90, %fd41, %fd64;
	sub.f64 	%fd91, %fd90, %fd41;
	sub.f64 	%fd92, %fd90, %fd91;
	sub.f64 	%fd93, %fd41, %fd92;
	sub.f64 	%fd94, %fd89, %fd91;
	add.f64 	%fd95, %fd94, %fd93;
	sub.f64 	%fd96, %fd43, %fd66;
	add.f64 	%fd97, %fd90, %fd96;
	sub.f64 	%fd98, %fd97, %fd90;
	sub.f64 	%fd99, %fd96, %fd98;
	add.f64 	%fd100, %fd95, %fd99;
	add.f64 	%fd101, %fd97, %fd100;
	sub.f64 	%fd102, %fd101, %fd97;
	sub.f64 	%fd103, %fd100, %fd102;
	add.f64 	%fd104, %fd86, %fd75;
	sub.f64 	%fd105, %fd104, %fd75;
	sub.f64 	%fd106, %fd104, %fd105;
	sub.f64 	%fd107, %fd75, %fd106;
	sub.f64 	%fd108, %fd86, %fd105;
	add.f64 	%fd109, %fd108, %fd107;
	add.f64 	%fd110, %fd88, %fd77;
	add.f64 	%fd111, %fd104, %fd110;
	sub.f64 	%fd112, %fd111, %fd104;
	sub.f64 	%fd113, %fd110, %fd112;
	add.f64 	%fd114, %fd109, %fd113;
	add.f64 	%fd115, %fd111, %fd114;
	sub.f64 	%fd116, %fd115, %fd111;
	sub.f64 	%fd117, %fd114, %fd116;
	add.f64 	%fd118, %fd146, %fd101;
	sub.f64 	%fd119, %fd118, %fd146;
	sub.f64 	%fd120, %fd118, %fd119;
	sub.f64 	%fd121, %fd146, %fd120;
	sub.f64 	%fd122, %fd101, %fd119;
	add.f64 	%fd123, %fd122, %fd121;
	add.f64 	%fd124, %fd147, %fd103;
	add.f64 	%fd125, %fd118, %fd124;
	sub.f64 	%fd126, %fd125, %fd118;
	sub.f64 	%fd127, %fd124, %fd126;
	add.f64 	%fd128, %fd123, %fd127;
	add.f64 	%fd146, %fd125, %fd128;
	sub.f64 	%fd129, %fd146, %fd125;
	add.f64 	%fd130, %fd148, %fd115;
	sub.f64 	%fd131, %fd130, %fd148;
	sub.f64 	%fd132, %fd130, %fd131;
	sub.f64 	%fd133, %fd148, %fd132;
	sub.f64 	%fd134, %fd115, %fd131;
	add.f64 	%fd135, %fd134, %fd133;
	add.f64 	%fd136, %fd149, %fd117;
	add.f64 	%fd137, %fd130, %fd136;
	sub.f64 	%fd138, %fd137, %fd130;
	sub.f64 	%fd139, %fd136, %fd138;
	add.f64 	%fd140, %fd135, %fd139;
	add.f64 	%fd148, %fd137, %fd140;
	sub.f64 	%fd141, %fd148, %fd137;
	sub.f64 	%fd149, %fd140, %fd141;
	sub.f64 	%fd147, %fd128, %fd129;
	add.s64 	%rd18, %rd18, 32;
	add.s64 	%rd17, %rd17, 32;
	add.s32 	%r14, %r14, 1;
	setp.lt.s32 	%p3, %r14, %r4;
	@%p3 bra 	$L__BB1_3;

$L__BB1_4:
	mov.u32 	%r13, %tid.x;
	mov.u32 	%r12, %ntid.x;
	mov.u32 	%r11, %ctaid.x;
	mad.lo.s32 	%r10, %r11, %r12, %r13;
	ld.param.u64 	%rd16, [_Z20dd_matrix_vector_mulP10dd_complexPKS_S2_i_param_0];
	cvta.to.global.u64 	%rd13, %rd16;
	mul.wide.s32 	%rd14, %r10, 32;
	add.s64 	%rd15, %rd13, %rd14;
	st.global.f64 	[%rd15], %fd146;
	st.global.f64 	[%rd15+8], %fd147;
	st.global.f64 	[%rd15+16], %fd148;
	st.global.f64 	[%rd15+24], %fd149;

$L__BB1_5:
	ret;

}
	// .globl	_Z23dd_deterministic_reduceP7dd_realPKS_i
.visible .entry _Z23dd_deterministic_reduceP7dd_realPKS_i(
	.param .u64 _Z23dd_deterministic_reduceP7dd_realPKS_i_param_0,
	.param .u64 _Z23dd_deterministic_reduceP7dd_realPKS_i_param_1,
	.param .u32 _Z23dd_deterministic_reduceP7dd_realPKS_i_param_2
)
{
	.reg .pred 	%p<9>;
	.reg .b32 	%r<18>;
	.reg .f64 	%fd<53>;
	.reg .b64 	%rd<11>;


	ld.param.u64 	%rd2, [_Z23dd_deterministic_reduceP7dd_realPKS_i_param_0];
	ld.param.u64 	%rd3, [_Z23dd_deterministic_reduceP7dd_realPKS_i_param_1];
	ld.param.u32 	%r11, [_Z23dd_deterministic_reduceP7dd_realPKS_i_param_2];
	cvta.to.global.u64 	%rd1, %rd3;
	mov.u32 	%r1, %ntid.x;
	shl.b32 	%r12, %r1, 1;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %tid.x;
	mad.lo.s32 	%r4, %r12, %r2, %r3;
	setp.ge.s32 	%p1, %r4, %r11;
	mov.f64 	%fd51, 0d0000000000000000;
	mov.f64 	%fd52, %fd51;
	@%p1 bra 	$L__BB2_3;

	mul.wide.s32 	%rd4, %r4, 16;
	add.s64 	%rd5, %rd1, %rd4;
	ld.global.nc.f64 	%fd51, [%rd5];
	ld.global.nc.f64 	%fd52, [%rd5+8];
	add.s32 	%r5, %r4, %r1;
	setp.ge.u32 	%p2, %r5, %r11;
	@%p2 bra 	$L__BB2_3;

	mul.wide.u32 	%rd6, %r5, 16;
	add.s64 	%rd7, %rd1, %rd6;
	ld.global.nc.f64 	%fd11, [%rd7];
	add.f64 	%fd12, %fd51, %fd11;
	sub.f64 	%fd13, %fd12, %fd51;
	sub.f64 	%fd14, %fd12, %fd13;
	sub.f64 	%fd15, %fd51, %fd14;
	sub.f64 	%fd16, %fd11, %fd13;
	add.f64 	%fd17, %fd16, %fd15;
	ld.global.nc.f64 	%fd18, [%rd7+8];
	add.f64 	%fd19, %fd52, %fd18;
	add.f64 	%fd20, %fd12, %fd19;
	sub.f64 	%fd21, %fd20, %fd12;
	sub.f64 	%fd22, %fd19, %fd21;
	add.f64 	%fd23, %fd17, %fd22;
	add.f64 	%fd51, %fd20, %fd23;
	sub.f64 	%fd24, %fd51, %fd20;
	sub.f64 	%fd52, %fd23, %fd24;

$L__BB2_3:
	shl.b32 	%r13, %r3, 4;
	mov.u32 	%r14, sdata;
	add.s32 	%r7, %r14, %r13;
	st.shared.v2.f64 	[%r7], {%fd51, %fd52};
	bar.sync 	0;
	shr.u32 	%r17, %r1, 1;
	setp.eq.s32 	%p3, %r17, 0;
	@%p3 bra 	$L__BB2_7;

$L__BB2_4:
	add.s32 	%r15, %r17, %r4;
	setp.ge.s32 	%p4, %r15, %r11;
	setp.ge.s32 	%p5, %r3, %r17;
	or.pred  	%p6, %p5, %p4;
	@%p6 bra 	$L__BB2_6;

	ld.shared.v2.f64 	{%fd25, %fd26}, [%r7];
	mad.lo.s32 	%r16, %r17, 16, %r7;
	ld.shared.v2.f64 	{%fd29, %fd30}, [%r16];
	add.f64 	%fd33, %fd25, %fd29;
	sub.f64 	%fd34, %fd33, %fd25;
	sub.f64 	%fd35, %fd33, %fd34;
	sub.f64 	%fd36, %fd25, %fd35;
	sub.f64 	%fd37, %fd29, %fd34;
	add.f64 	%fd38, %fd37, %fd36;
	add.f64 	%fd39, %fd26, %fd30;
	add.f64 	%fd40, %fd39, %fd33;
	sub.f64 	%fd41, %fd40, %fd33;
	sub.f64 	%fd42, %fd39, %fd41;
	add.f64 	%fd43, %fd42, %fd38;
	add.f64 	%fd44, %fd40, %fd43;
	sub.f64 	%fd45, %fd44, %fd40;
	sub.f64 	%fd46, %fd43, %fd45;
	st.shared.v2.f64 	[%r7], {%fd44, %fd46};

$L__BB2_6:
	bar.sync 	0;
	shr.u32 	%r17, %r17, 1;
	setp.ne.s32 	%p7, %r17, 0;
	@%p7 bra 	$L__BB2_4;

$L__BB2_7:
	setp.ne.s32 	%p8, %r3, 0;
	@%p8 bra 	$L__BB2_9;

	ld.shared.v2.f64 	{%fd47, %fd48}, [sdata];
	cvta.to.global.u64 	%rd8, %rd2;
	mul.wide.u32 	%rd9, %r2, 16;
	add.s64 	%rd10, %rd8, %rd9;
	st.global.f64 	[%rd10], %fd47;
	st.global.f64 	[%rd10+8], %fd48;

$L__BB2_9:
	ret;

}
	// .globl	_Z18test_dd_arithmeticv
.visible .entry _Z18test_dd_arithmeticv()
{
	.local .align 16 .b8 	__local_depot3[48];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<2>;
	.reg .b32 	%r<8>;
	.reg .f64 	%fd<7>;
	.reg .b64 	%rd<17>;


	mov.u64 	%SPL, __local_depot3;
	cvta.local.u64 	%SP, %SPL;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	or.b32  	%r3, %r2, %r1;
	setp.ne.s32 	%p1, %r3, 0;
	@%p1 bra 	$L__BB3_2;

	add.u64 	%rd1, %SP, 32;
	add.u64 	%rd2, %SPL, 32;
	mov.u64 	%rd3, $str$1;
	cvta.global.u64 	%rd4, %rd3;
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd4;
	.param .b64 param1;
	st.param.b64 	[param1+0], 0;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r4, [retval0+0];
	} // callseq 0
	add.u64 	%rd5, %SP, 0;
	add.u64 	%rd6, %SPL, 0;
	mov.u64 	%rd7, $str$2;
	cvta.global.u64 	%rd8, %rd7;
	mov.u64 	%rd9, 4602249904922421150;
	st.local.v2.u64 	[%rd6], {%rd8, %rd9};
	mov.f64 	%fd1, 0d3FDE79E79E79E79E;
	mov.f64 	%fd2, 0d3C7E79E79E79E79E;
	st.local.v2.f64 	[%rd6+16], {%fd2, %fd1};
	mov.u64 	%rd10, $str;
	cvta.global.u64 	%rd11, %rd10;
	{ // callseq 1, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd11;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd5;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r5, [retval0+0];
	} // callseq 1
	mov.u64 	%rd12, $str$3;
	cvta.global.u64 	%rd13, %rd12;
	mov.u64 	%rd14, 4620997061037642869;
	st.local.v2.u64 	[%rd6], {%rd13, %rd14};
	mov.f64 	%fd3, 0d402114580B45D475;
	mov.f64 	%fd4, 0dBCC867BDEA1974BC;
	st.local.v2.f64 	[%rd6+16], {%fd4, %fd3};
	{ // callseq 2, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd11;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd5;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r6, [retval0+0];
	} // callseq 2
	mov.f64 	%fd5, 0d3FF0000000000000;
	mov.f64 	%fd6, 0d4008000000000000;
	st.local.v2.f64 	[%rd2], {%fd6, %fd5};
	mov.u64 	%rd15, $str$4;
	cvta.global.u64 	%rd16, %rd15;
	{ // callseq 3, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd16;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd1;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r7, [retval0+0];
	} // callseq 3

$L__BB3_2:
	ret;

}

