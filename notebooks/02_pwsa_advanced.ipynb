{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Advanced PWSA Features\n",
    "\n",
    "This notebook demonstrates advanced Prompt Weapon System Awareness (PWSA) capabilities including:\n",
    "\n",
    "1. Multi-sensor fusion\n",
    "2. Pixel-level IR processing\n",
    "3. Trajectory prediction\n",
    "4. Threat prioritization\n",
    "5. Real-time tracking\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "```bash\n",
    "pip install requests numpy pandas matplotlib opencv-python scipy\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import display, clear_output\n",
    "import cv2\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "# Configuration\n",
    "API_KEY = \"your-api-key-here\"\n",
    "BASE_URL = \"http://localhost:8080\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "print(\"✓ Imports loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1. Multi-Sensor Fusion\n",
    "\n",
    "Combine data from multiple sensors (IR, radar, optical) for improved detection accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic multi-sensor data\n",
    "def generate_sensor_data(sv_id: int, num_targets: int = 3) -> Dict:\n",
    "    \"\"\"Generate synthetic sensor readings with multiple targets.\"\"\"\n",
    "    targets = []\n",
    "    for i in range(num_targets):\n",
    "        # Random position in sensor FOV\n",
    "        azimuth = np.random.uniform(-30, 30)  # degrees\n",
    "        elevation = np.random.uniform(-15, 15)  # degrees\n",
    "        range_km = np.random.uniform(5, 50)  # km\n",
    "        \n",
    "        targets.append({\n",
    "            \"id\": f\"target_{i}\",\n",
    "            \"azimuth\": azimuth,\n",
    "            \"elevation\": elevation,\n",
    "            \"range\": range_km,\n",
    "            \"velocity\": np.random.uniform(200, 800),  # m/s\n",
    "            \"ir_signature\": np.random.uniform(0.6, 0.95),\n",
    "            \"radar_cross_section\": np.random.uniform(0.1, 2.0),  # m²\n",
    "        })\n",
    "    \n",
    "    return {\n",
    "        \"sv_id\": sv_id,\n",
    "        \"timestamp\": int(time.time()),\n",
    "        \"sensors\": {\n",
    "            \"ir\": {\n",
    "                \"frame_id\": np.random.randint(1000, 9999),\n",
    "                \"targets\": targets\n",
    "            },\n",
    "            \"radar\": {\n",
    "                \"scan_id\": np.random.randint(1000, 9999),\n",
    "                \"targets\": targets\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Fuse sensor data\n",
    "sensor_data = generate_sensor_data(sv_id=42, num_targets=5)\n",
    "\n",
    "response = requests.post(\n",
    "    f\"{BASE_URL}/api/v1/pwsa/fuse\",\n",
    "    headers=headers,\n",
    "    json=sensor_data\n",
    ")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    result = response.json()['data']\n",
    "    print(f\"Sensor Fusion Results:\")\n",
    "    print(f\"  Fused Tracks: {result['num_tracks']}\")\n",
    "    print(f\"  Fusion Quality: {result['fusion_quality']:.2%}\")\n",
    "    print(f\"  Processing Time: {result['processing_time_ms']:.1f}ms\\n\")\n",
    "    \n",
    "    print(\"Track Details:\")\n",
    "    for track in result['tracks']:\n",
    "        print(f\"  Track {track['track_id']}:\")\n",
    "        print(f\"    Position: ({track['position'][0]:.1f}, {track['position'][1]:.1f}, {track['position'][2]:.1f})\")\n",
    "        print(f\"    Velocity: {track['velocity']:.0f} m/s\")\n",
    "        print(f\"    Confidence: {track['confidence']:.2%}\")\n",
    "        print(f\"    Threat Level: {track['threat_level']}\\n\")\nelse:\n",
    "    print(f\"Error: {response.status_code}\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 2. Pixel-Level IR Processing\n",
    "\n",
    "Process raw IR frame pixels for detailed thermal analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic IR frame\n",
    "def generate_ir_frame(width: int = 640, height: int = 480, num_hotspots: int = 3) -> np.ndarray:\n",
    "    \"\"\"Generate synthetic IR frame with thermal hotspots.\"\"\"\n",
    "    # Base thermal noise\n",
    "    frame = np.random.normal(loc=128, scale=20, size=(height, width))\n",
    "    \n",
    "    # Add hotspots (potential threats)\n",
    "    for _ in range(num_hotspots):\n",
    "        cx = np.random.randint(50, width - 50)\n",
    "        cy = np.random.randint(50, height - 50)\n",
    "        size = np.random.randint(10, 30)\n",
    "        intensity = np.random.uniform(200, 255)\n",
    "        \n",
    "        # Gaussian hotspot\n",
    "        y, x = np.ogrid[-cy:height-cy, -cx:width-cx]\n",
    "        mask = x*x + y*y <= size*size\n",
    "        frame[mask] = intensity * np.exp(-(x[mask]**2 + y[mask]**2) / (2 * (size/2)**2))\n",
    "    \n",
    "    return np.clip(frame, 0, 255).astype(np.uint8)\n",
    "\n",
    "# Generate and visualize IR frame\n",
    "ir_frame = generate_ir_frame(num_hotspots=5)\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(ir_frame, cmap='hot', interpolation='nearest')\n",
    "plt.title('Raw IR Frame')\n",
    "plt.colorbar(label='Thermal Intensity')\n",
    "plt.xlabel('X (pixels)')\n",
    "plt.ylabel('Y (pixels)')\n",
    "\n",
    "# Process frame via API\n",
    "pixel_request = {\n",
    "    \"frame_id\": int(time.time()),\n",
    "    \"width\": ir_frame.shape[1],\n",
    "    \"height\": ir_frame.shape[0],\n",
    "    \"pixels\": ir_frame.flatten().tolist(),  # Flattened pixel array\n",
    "    \"processing_options\": {\n",
    "        \"detect_hotspots\": True,\n",
    "        \"compute_entropy\": True,\n",
    "        \"apply_tda\": True\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.post(\n",
    "    f\"{BASE_URL}/api/v1/pixels/process\",\n",
    "    headers=headers,\n",
    "    json=pixel_request\n",
    ")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    result = response.json()['data']\n",
    "    \n",
    "    # Visualize processed frame\n",
    "    processed_pixels = np.array(result['processed_pixels']).reshape(ir_frame.shape)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(processed_pixels, cmap='hot', interpolation='nearest')\n",
    "    plt.title('Processed IR Frame')\n",
    "    plt.colorbar(label='Enhanced Intensity')\n",
    "    plt.xlabel('X (pixels)')\n",
    "    plt.ylabel('Y (pixels)')\n",
    "    \n",
    "    # Mark detected hotspots\n",
    "    for hotspot in result['hotspots']:\n",
    "        plt.plot(hotspot['x'], hotspot['y'], 'c+', markersize=15, markeredgewidth=2)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nProcessing Results:\")\n",
    "    print(f\"  Hotspots Detected: {len(result['hotspots'])}\")\n",
    "    print(f\"  Frame Entropy: {result['entropy']:.3f}\")\n",
    "    print(f\"  TDA Features: {len(result['tda_features'])} topological features\")\n",
    "    print(f\"  Processing Time: {result['processing_time_ms']:.1f}ms\")\n",
    "    \n",
    "    print(\"\\nHotspot Details:\")\n",
    "    for i, hotspot in enumerate(result['hotspots']):\n",
    "        print(f\"  Hotspot {i+1}: ({hotspot['x']}, {hotspot['y']}) - Intensity: {hotspot['intensity']:.1f}\")\nelse:\n",
    "    print(f\"Error: {response.status_code}\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## 3. Trajectory Prediction\n",
    "\n",
    "Predict future trajectory of detected threats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Historical track data\n",
    "def generate_track_history(num_points: int = 10) -> List[Dict]:\n",
    "    \"\"\"Generate synthetic track history for a ballistic trajectory.\"\"\"\n",
    "    t = np.linspace(0, 100, num_points)  # Time in seconds\n",
    "    \n",
    "    # Ballistic trajectory (simplified)\n",
    "    v0 = 800  # m/s initial velocity\n",
    "    angle = np.radians(45)  # Launch angle\n",
    "    g = 9.81  # m/s²\n",
    "    \n",
    "    x = v0 * np.cos(angle) * t\n",
    "    y = v0 * np.sin(angle) * t - 0.5 * g * t**2\n",
    "    z = np.zeros_like(t)  # Assuming 2D for simplicity\n",
    "    \n",
    "    # Add noise\n",
    "    x += np.random.normal(0, 50, size=len(t))\n",
    "    y += np.random.normal(0, 50, size=len(t))\n",
    "    \n",
    "    history = []\n",
    "    for i in range(num_points):\n",
    "        history.append({\n",
    "            \"timestamp\": int(time.time()) - (num_points - i) * 10,\n",
    "            \"position\": [float(x[i]), float(y[i]), float(z[i])],\n",
    "            \"velocity\": [float(v0 * np.cos(angle)), float(v0 * np.sin(angle) - g * t[i]), 0.0]\n",
    "        })\n",
    "    \n",
    "    return history\n",
    "\n",
    "track_history = generate_track_history(15)\n",
    "\n",
    "# Predict trajectory\n",
    "prediction_request = {\n",
    "    \"track_id\": \"threat_001\",\n",
    "    \"history\": track_history,\n",
    "    \"prediction_horizon\": 30,  # seconds\n",
    "    \"model\": \"kalman_filter\"  # or \"neural_network\"\n",
    "}\n",
    "\n",
    "response = requests.post(\n",
    "    f\"{BASE_URL}/api/v1/pwsa/predict\",\n",
    "    headers=headers,\n",
    "    json=prediction_request\n",
    ")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    result = response.json()['data']\n",
    "    \n",
    "    # Visualize trajectory\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Historical track\n",
    "    hist_x = [p['position'][0] for p in track_history]\n",
    "    hist_y = [p['position'][1] for p in track_history]\n",
    "    plt.plot(hist_x, hist_y, 'bo-', label='Historical Track', linewidth=2, markersize=6)\n",
    "    \n",
    "    # Predicted trajectory\n",
    "    pred_x = [p['position'][0] for p in result['predictions']]\n",
    "    pred_y = [p['position'][1] for p in result['predictions']]\n",
    "    plt.plot(pred_x, pred_y, 'r--', label='Predicted Trajectory', linewidth=2)\n",
    "    \n",
    "    # Uncertainty bounds\n",
    "    if 'uncertainty' in result:\n",
    "        std_x = [u['std'][0] for u in result['uncertainty']]\n",
    "        std_y = [u['std'][1] for u in result['uncertainty']]\n",
    "        plt.fill_between(\n",
    "            pred_x,\n",
    "            np.array(pred_y) - 2*np.array(std_y),\n",
    "            np.array(pred_y) + 2*np.array(std_y),\n",
    "            alpha=0.3,\n",
    "            color='red',\n",
    "            label='95% Confidence'\n",
    "        )\n",
    "    \n",
    "    # Impact point\n",
    "    if result['impact_point']:\n",
    "        impact = result['impact_point']\n",
    "        plt.plot(impact['position'][0], impact['position'][1], 'kx', \n",
    "                markersize=20, markeredgewidth=3, label='Predicted Impact')\n",
    "    \n",
    "    plt.xlabel('X Position (m)')\n",
    "    plt.ylabel('Y Position (m)')\n",
    "    plt.title('Threat Trajectory Prediction')\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.axis('equal')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nTrajectory Prediction Results:\")\n",
    "    print(f\"  Model Used: {result['model']}\")\n",
    "    print(f\"  Prediction Confidence: {result['confidence']:.2%}\")\n",
    "    print(f\"  Time to Impact: {result['time_to_impact']:.1f}s\")\n",
    "    if result['impact_point']:\n",
    "        print(f\"  Impact Position: ({result['impact_point']['position'][0]:.0f}, {result['impact_point']['position'][1]:.0f}, {result['impact_point']['position'][2]:.0f})\")\n",
    "    print(f\"  Computation Time: {result['computation_time_ms']:.1f}ms\")\nelse:\n",
    "    print(f\"Error: {response.status_code}\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## 4. Threat Prioritization\n",
    "\n",
    "Prioritize multiple threats based on risk assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple threats\n",
    "threats = [\n",
    "    {\n",
    "        \"threat_id\": \"T001\",\n",
    "        \"type\": \"ballistic_missile\",\n",
    "        \"position\": [50000, 30000, 20000],\n",
    "        \"velocity\": 2500,\n",
    "        \"time_to_impact\": 180,\n",
    "        \"confidence\": 0.95\n",
    "    },\n",
    "    {\n",
    "        \"threat_id\": \"T002\",\n",
    "        \"type\": \"cruise_missile\",\n",
    "        \"position\": [30000, 15000, 5000],\n",
    "        \"velocity\": 800,\n",
    "        \"time_to_impact\": 120,\n",
    "        \"confidence\": 0.88\n",
    "    },\n",
    "    {\n",
    "        \"threat_id\": \"T003\",\n",
    "        \"type\": \"aircraft\",\n",
    "        \"position\": [80000, 40000, 10000],\n",
    "        \"velocity\": 600,\n",
    "        \"time_to_impact\": 300,\n",
    "        \"confidence\": 0.72\n",
    "    },\n",
    "    {\n",
    "        \"threat_id\": \"T004\",\n",
    "        \"type\": \"hypersonic\",\n",
    "        \"position\": [100000, 80000, 30000],\n",
    "        \"velocity\": 5000,\n",
    "        \"time_to_impact\": 90,\n",
    "        \"confidence\": 0.82\n",
    "    }\n",
    "]\n",
    "\n",
    "prioritization_request = {\n",
    "    \"threats\": threats,\n",
    "    \"prioritization_strategy\": \"time_weighted_risk\",\n",
    "    \"defensive_assets\": {\n",
    "        \"interceptors_available\": 10,\n",
    "        \"max_engagement_range\": 100000\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.post(\n",
    "    f\"{BASE_URL}/api/v1/pwsa/prioritize\",\n",
    "    headers=headers,\n",
    "    json=prioritization_request\n",
    ")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    result = response.json()['data']\n",
    "    \n",
    "    print(\"Threat Prioritization Results:\\n\")\n",
    "    print(f\"{'Rank':<6} {'Threat ID':<12} {'Type':<20} {'Risk Score':<12} {'TTI (s)':<10} {'Action':<20}\")\n",
    "    print(\"=\" * 95)\n",
    "    \n",
    "    for i, threat in enumerate(result['prioritized_threats'], 1):\n",
    "        print(f\"{i:<6} {threat['threat_id']:<12} {threat['type']:<20} \"\n",
    "              f\"{threat['risk_score']:>6.3f}      {threat['time_to_impact']:>6.0f}    \"\n",
    "              f\"{threat['recommended_action']:<20}\")\n",
    "    \n",
    "    print(f\"\\n{'='*95}\")\n",
    "    print(f\"Prioritization Strategy: {result['strategy_used']}\")\n",
    "    print(f\"Total Threats: {result['total_threats']}\")\n",
    "    print(f\"Engageable Threats: {result['engageable_threats']}\")\n",
    "    print(f\"Processing Time: {result['processing_time_ms']:.1f}ms\")\n",
    "    \n",
    "    # Visualize threat priorities\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Risk scores\n",
    "    threat_ids = [t['threat_id'] for t in result['prioritized_threats']]\n",
    "    risk_scores = [t['risk_score'] for t in result['prioritized_threats']]\n",
    "    colors = ['red' if s > 0.8 else 'orange' if s > 0.6 else 'yellow' for s in risk_scores]\n",
    "    \n",
    "    ax1.barh(threat_ids, risk_scores, color=colors, edgecolor='black')\n",
    "    ax1.set_xlabel('Risk Score')\n",
    "    ax1.set_title('Threat Risk Scores')\n",
    "    ax1.set_xlim(0, 1)\n",
    "    ax1.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # Time to impact\n",
    "    tti_values = [t['time_to_impact'] for t in result['prioritized_threats']]\n",
    "    ax2.barh(threat_ids, tti_values, color='steelblue', edgecolor='black')\n",
    "    ax2.set_xlabel('Time to Impact (s)')\n",
    "    ax2.set_title('Threat Timeline')\n",
    "    ax2.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\nelse:\n",
    "    print(f\"Error: {response.status_code}\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## 5. Real-Time Tracking Simulation\n",
    "\n",
    "Simulate real-time threat tracking with continuous updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import queue\n",
    "\n",
    "# Tracking simulation\n",
    "class ThreatTracker:\n",
    "    def __init__(self, base_url: str, headers: dict):\n",
    "        self.base_url = base_url\n",
    "        self.headers = headers\n",
    "        self.tracks = {}\n",
    "        self.updates = queue.Queue()\n",
    "        self.running = False\n",
    "    \n",
    "    def update_track(self, sensor_data: Dict) -> Dict:\n",
    "        \"\"\"Update track with new sensor data.\"\"\"\n",
    "        response = requests.post(\n",
    "            f\"{self.base_url}/api/v1/pwsa/track\",\n",
    "            headers=self.headers,\n",
    "            json=sensor_data\n",
    "        )\n",
    "        if response.status_code == 200:\n",
    "            return response.json()['data']\n",
    "        return None\n",
    "    \n",
    "    def simulate_tracking(self, duration: int = 10, update_rate: float = 1.0):\n",
    "        \"\"\"Simulate tracking for specified duration.\"\"\"\n",
    "        print(f\"Starting tracking simulation for {duration}s...\\n\")\n",
    "        start_time = time.time()\n",
    "        iteration = 0\n",
    "        \n",
    "        while time.time() - start_time < duration:\n",
    "            iteration += 1\n",
    "            \n",
    "            # Generate simulated sensor update\n",
    "            sensor_data = {\n",
    "                \"sv_id\": 42,\n",
    "                \"timestamp\": int(time.time()),\n",
    "                \"ir_frame\": {\n",
    "                    \"width\": 640,\n",
    "                    \"height\": 480,\n",
    "                    \"centroid_x\": 320.0 + np.random.normal(0, 10),\n",
    "                    \"centroid_y\": 240.0 + np.random.normal(0, 10),\n",
    "                    \"hotspot_count\": np.random.randint(3, 8)\n",
    "                },\n",
    "                \"radar\": {\n",
    "                    \"range\": 25000 + np.random.normal(0, 500),\n",
    "                    \"azimuth\": np.random.uniform(-5, 5),\n",
    "                    \"elevation\": np.random.uniform(-2, 2)\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            # Update track\n",
    "            result = self.update_track(sensor_data)\n",
    "            \n",
    "            if result:\n",
    "                clear_output(wait=True)\n",
    "                print(f\"Tracking Update #{iteration} (t={time.time()-start_time:.1f}s)\")\n",
    "                print(\"=\" * 60)\n",
    "                print(f\"Active Tracks: {result['active_tracks']}\")\n",
    "                print(f\"New Detections: {result['new_detections']}\")\n",
    "                print(f\"Lost Tracks: {result['lost_tracks']}\")\n",
    "                print(f\"Processing Latency: {result['latency_ms']:.1f}ms\\n\")\n",
    "                \n",
    "                if result['tracks']:\n",
    "                    print(f\"{'Track ID':<12} {'Position':<30} {'Velocity':<12} {'Confidence':<12}\")\n",
    "                    print(\"-\" * 70)\n",
    "                    for track in result['tracks']:\n",
    "                        pos = track['position']\n",
    "                        print(f\"{track['track_id']:<12} \"\n",
    "                              f\"({pos[0]:>7.0f}, {pos[1]:>7.0f}, {pos[2]:>7.0f})  \"\n",
    "                              f\"{track['velocity']:>8.0f} m/s  \"\n",
    "                              f\"{track['confidence']:>8.1%}\")\n",
    "            \n",
    "            time.sleep(update_rate)\n",
    "        \n",
    "        print(f\"\\nTracking simulation complete.\")\n",
    "\n",
    "# Run simulation\n",
    "tracker = ThreatTracker(BASE_URL, headers)\n",
    "tracker.simulate_tracking(duration=15, update_rate=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This tutorial demonstrated advanced PWSA capabilities:\n",
    "\n",
    "1. ✓ Multi-sensor fusion for improved detection accuracy\n",
    "2. ✓ Pixel-level IR processing with hotspot detection\n",
    "3. ✓ Trajectory prediction with uncertainty quantification\n",
    "4. ✓ Threat prioritization using risk assessment\n",
    "5. ✓ Real-time tracking simulation\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Explore `03_llm_consensus.ipynb` for multi-model AI queries\n",
    "- See `04_pixel_processing.ipynb` for advanced image analysis\n",
    "- Check [PWSA Documentation](../docs/API.md#pwsa-endpoints) for all endpoints\n",
    "- Review [Architecture Guide](../docs/ARCHITECTURE.md) for system design"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
