"""
Graph Coloring Dataset Loader for PyTorch Geometric

Loads 15k training graphs from JSON format generated by Rust.
Optimized for H100 GPU training.
"""

import json
import numpy as np
import torch
from torch_geometric.data import Data, Dataset
from pathlib import Path
from typing import List, Tuple
import os


class GraphColoringDataset(Dataset):
    """Dataset for graph coloring with multi-task learning"""

    def __init__(self, root: str, split: str = 'train', max_colors: int = 200):
        """
        Args:
            root: Path to training_data directory
            split: 'train' or 'val'
            max_colors: Maximum number of colors (for one-hot encoding)
        """
        self.root = Path(root)
        self.split = split
        self.max_colors = max_colors

        # Load file paths
        self.graph_dir = self.root / 'graphs'
        self.file_list = sorted(self.graph_dir.glob(f'{split}_*.json'))

        print(f"[Dataset] Loaded {len(self.file_list)} {split} graphs from {self.graph_dir}")

        # Load metadata
        metadata_path = self.root / 'metadata.json'
        if metadata_path.exists():
            with open(metadata_path) as f:
                self.metadata = json.load(f)
                print(f"[Dataset] Metadata: {self.metadata}")
        else:
            self.metadata = {}

        super().__init__(str(root))

    def len(self):
        return len(self.file_list)

    def get(self, idx):
        """Load and convert a single graph to PyG Data object"""
        file_path = self.file_list[idx]

        with open(file_path) as f:
            graph_data = json.load(f)

        # Parse adjacency matrix
        adj_data = graph_data['adjacency']['data']
        n = graph_data['n']

        # Reconstruct adjacency matrix
        adjacency = np.array(adj_data, dtype=np.uint8).reshape(n, n)

        # Convert to edge_index (COO format)
        edge_index = self._adjacency_to_edge_index(adjacency)

        # Node features (16-dim as specified)
        node_features = np.array(graph_data['node_features'], dtype=np.float32)

        # Ground truth labels
        ground_truth = graph_data['ground_truth']
        node_colors = np.array(ground_truth['node_colors'], dtype=np.int64)
        chromatic_number = ground_truth['chromatic_number']
        graph_type_id = ground_truth['graph_type_id']
        difficulty = ground_truth['difficulty']

        # Convert to PyTorch tensors
        x = torch.from_numpy(node_features).float()
        edge_index = torch.from_numpy(edge_index).long()

        # Labels for multi-task learning
        y_colors = torch.from_numpy(node_colors).long()  # [N] node colors
        y_chromatic = torch.tensor([chromatic_number], dtype=torch.float32)  # [1] chromatic number
        y_graph_type = torch.tensor([graph_type_id], dtype=torch.long)  # [1] graph type
        y_difficulty = torch.tensor([difficulty], dtype=torch.float32)  # [1] difficulty score

        # Create PyG Data object
        data = Data(
            x=x,
            edge_index=edge_index,
            y_colors=y_colors,
            y_chromatic=y_chromatic,
            y_graph_type=y_graph_type,
            y_difficulty=y_difficulty,
            num_nodes=n,
        )

        return data

    @staticmethod
    def _adjacency_to_edge_index(adjacency: np.ndarray) -> np.ndarray:
        """Convert boolean adjacency matrix to edge_index [2, E]"""
        edges = np.argwhere(adjacency > 0)  # [E, 2]
        if len(edges) == 0:
            # Empty graph - return minimal edge list
            return np.array([[0], [0]], dtype=np.int64)
        edge_index = edges.T  # [2, E]
        return edge_index.astype(np.int64)


def collate_batch(batch: List[Data]) -> Data:
    """Custom collate function for batching graphs"""
    from torch_geometric.data import Batch
    return Batch.from_data_list(batch)


if __name__ == '__main__':
    # Test dataset loading
    print("Testing dataset loading...")

    dataset = GraphColoringDataset(
        root='../../training_data',
        split='train',
        max_colors=200
    )

    print(f"Total graphs: {len(dataset)}")

    # Load first graph
    data = dataset[0]
    print(f"\nFirst graph:")
    print(f"  Nodes: {data.num_nodes}")
    print(f"  Edges: {data.edge_index.shape[1]}")
    print(f"  Node features: {data.x.shape}")
    print(f"  Chromatic number: {data.y_chromatic.item()}")
    print(f"  Graph type: {data.y_graph_type.item()}")
    print(f"  Difficulty: {data.y_difficulty.item()}")

    # Test batching
    from torch.utils.data import DataLoader
    loader = DataLoader(dataset, batch_size=8, shuffle=True, collate_fn=collate_batch)

    batch = next(iter(loader))
    print(f"\nBatch test:")
    print(f"  Batched nodes: {batch.num_nodes}")
    print(f"  Batched edges: {batch.edge_index.shape[1]}")
    print(f"  Batch size: {batch.num_graphs}")

    print("\nâœ… Dataset loading successful!")
