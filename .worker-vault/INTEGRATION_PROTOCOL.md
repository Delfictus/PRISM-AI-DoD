# Worker 1 Integration Protocol

**Version**: 1.0
**Last Updated**: 2025-10-13
**Status**: ‚úÖ ACTIVE

---

## Overview

This document defines the integration protocol for Worker 1's deliverables with other workers in the 8-Worker development plan.

**Worker 1 Deliverables**:
- Transfer Entropy (KSG algorithm, GPU-accelerated)
  - **Phase 1**: High-accuracy TE (KD-tree, Conditional TE, Bootstrap CI)
  - **Phase 2**: Performance optimizations (Incremental TE, Memory-efficient, Adaptive embedding, Symbolic TE)
  - **Phase 3**: Research extensions (PID, Multiple testing correction)
- Thermodynamic Routing (energy models, temperature schedules, replica exchange)
- Active Inference (hierarchical inference, policy search)
- Time Series Forecasting (ARIMA, LSTM/GRU, uncertainty quantification, Kalman Filter)

**Dependent Workers**: 3, 5, 7
**Optional Enhancement**: Worker 2 (GPU kernels)

---

## Integration Timeline

### Week 5: Time Series Integration Week ‚è≥

**Monday** - Worker 1 Deliverables Ready ‚úÖ
- [x] Time series module published (d9ad504)
- [x] API documentation complete
- [x] Integration examples provided
- [x] CPU fallbacks functional

**Tuesday-Thursday** - Dependent Workers Integrate:

**Worker 3 (PWSA)**:
- [ ] Import Worker 1 time series module
- [ ] Integrate trajectory forecasting
- [ ] Test with historical satellite tracks
- [ ] Validate forecast accuracy

**Worker 5 (LLM)**:
- [ ] Import Worker 1 thermodynamic + time series
- [ ] Integrate cost forecasting
- [ ] Test proactive model selection
- [ ] Measure cost savings

**Worker 7 (Robotics)**:
- [ ] Import Worker 1 time series + active inference
- [ ] Integrate environment prediction
- [ ] Test motion planning with forecasts
- [ ] Validate safety improvements

**Friday** - Integration Testing:
- [ ] Cross-domain integration tests
- [ ] Performance benchmarking
- [ ] Bug fixes and optimization
- [ ] Week 5 deliverables merged

---

## Integration Steps (For Dependent Workers)

### Step 1: Branch Merge

```bash
# Navigate to your worktree
cd /home/diddy/Desktop/PRISM-Worker-{N}

# Fetch Worker 1's branch
git fetch origin worker-1-ai-core

# Merge into your branch
git merge origin/worker-1-ai-core

# Resolve conflicts if any
git status
# (fix conflicts)
git add -A
git commit -m "chore: merge Worker 1 deliverables"
```

### Step 2: Verify Build

```bash
# Build library with Worker 1's modules
cargo build --lib --features cuda

# Expected: Successful build (warnings OK, 0 errors)
# If build fails, check:
#   1. Cargo.toml dependencies
#   2. Feature flags
#   3. Import paths
```

### Step 3: Import Modules

Add to your Rust file:

```rust
// Transfer Entropy (Core)
use prism_ai::{detect_causal_direction, CausalDirection};

// Transfer Entropy (Phase 1: High-Accuracy)
use prism_ai::{KsgEstimator, ConditionalTe, BootstrapResampler, BootstrapMethod, KdTree};

// Transfer Entropy (Phase 2: Performance)
use prism_ai::{IncrementalTe, AdaptiveEmbedding, SymbolicTe, CompressedHistogram};

// Transfer Entropy (Phase 3: Research)
use prism_ai::{PartialInfoDecomp, PidMethod, MultipleTestingCorrection, CorrectionMethod};

// Thermodynamic
use prism_ai::{ThermodynamicNetwork, NetworkConfig};

// Active Inference
use prism_ai::{HierarchicalModel, StateSpaceLevel, PolicySelector};

// Time Series
use prism_ai::{TimeSeriesForecaster, ArimaConfig, LstmConfig, CellType, KalmanFilter};
```

### Step 4: Test Integration

```bash
# Run Worker 1's tests to verify functionality
cargo test --lib time_series --features cuda
cargo test --lib orchestration::thermodynamic --features cuda

# Run your integration tests
cargo test --lib <your_module> --features cuda
```

### Step 5: Document Integration

Update your `.worker-vault/Progress/DAILY_PROGRESS.md`:

```markdown
## Week 5, Day 1: Worker 1 Integration

- [x] Merged Worker 1 deliverables (time series, thermodynamic, etc.)
- [x] Verified build successful
- [x] Tested Worker 1 APIs
- [x] Started integration with <your domain>
```

---

## Integration Patterns

### Pattern 1: Transfer Entropy for Coupling Detection

**Use Case**: Detect causal relationships before forecasting

```rust
use prism_ai::{detect_causal_direction, CausalDirection};

// Step 1: Detect coupling
let coupling = detect_causal_direction(
    &series_x,
    &series_y,
    embedding_dim: 2,
    delay: 1,
    k_neighbors: 5
)?;

// Step 2: Use coupling strength for decisions
match coupling.direction {
    CausalDirection::XToY if coupling.te_x_to_y > 0.5 => {
        println!("Strong X‚ÜíY causation detected");
        // Use X to predict Y
    }
    CausalDirection::Independent => {
        println!("Series are independent");
        // Forecast separately
    }
    _ => {
        println!("Weak or bidirectional coupling");
        // Handle accordingly
    }
}
```

**Best For**:
- PWSA: Satellite track coupling
- LLM: Model interaction analysis
- Robotics: Multi-agent interactions

---

### Pattern 2: Time Series ‚Üí Decision Making

**Use Case**: Forecast then act on prediction

```rust
use prism_ai::{TimeSeriesForecaster, ArimaConfig};

// Step 1: Forecast
let mut forecaster = TimeSeriesForecaster::new();

let arima_config = ArimaConfig {
    p: 2, d: 1, q: 1,
    include_constant: true,
};

forecaster.fit_arima(&historical_data, arima_config)?;
let forecast = forecaster.forecast_arima(horizon: 10)?;

// Step 2: Make decisions based on forecast
for (t, predicted_value) in forecast.iter().enumerate() {
    if predicted_value > &threshold {
        println!("T+{}: High value predicted, taking action", t);
        // Take proactive action
    }
}
```

**Best For**:
- PWSA: Trajectory prediction ‚Üí intercept planning
- Finance: Price forecast ‚Üí portfolio adjustment
- LLM: Cost forecast ‚Üí model selection
- Robotics: Obstacle forecast ‚Üí path planning

---

### Pattern 3: Thermodynamic Consensus

**Use Case**: Multi-model decision with temperature annealing

```rust
use prism_ai::{ThermodynamicNetwork, NetworkConfig};

// Step 1: Create thermodynamic network
let config = NetworkConfig {
    num_nodes: 6,  // Number of models/options
    coupling_strength: 1.0,
    temperature: 1.0,
    dt: 0.01,
    dissipation: 0.1,
};

let mut network = ThermodynamicNetwork::new(config);

// Step 2: Evolve to equilibrium
for _ in 0..1000 {
    network.step()?;
}

// Step 3: Extract consensus
let state = network.get_state();
println!("Free Energy: {:.4}", state.free_energy);
println!("Entropy: {:.4}", state.entropy);

// Lower free energy = better consensus
```

**Best For**:
- LLM: Multi-model routing with consensus
- Finance: Portfolio optimization with multiple strategies
- Any multi-option decision-making

---

### Pattern 4: Hierarchical Active Inference

**Use Case**: Multi-level decision-making with belief propagation

```rust
use prism_ai::{HierarchicalModel, StateSpaceLevel};

// Step 1: Define hierarchy
let levels = vec![
    StateSpaceLevel {
        state_dim: 2,      // Low-level
        obs_dim: 2,
        precision: 1.0,
        learning_rate: 0.01,
        timescale: 1.0,    // Fast (10ms)
    },
    StateSpaceLevel {
        state_dim: 4,      // Mid-level
        obs_dim: 2,
        precision: 0.5,
        learning_rate: 0.005,
        timescale: 100.0,  // Medium (1s)
    },
    StateSpaceLevel {
        state_dim: 8,      // High-level
        obs_dim: 4,
        precision: 0.1,
        learning_rate: 0.001,
        timescale: 6000.0, // Slow (60s)
    },
];

let mut model = HierarchicalModel::new(levels);

// Step 2: Process observation
let observation = vec![0.5, 0.3];
model.infer_states(&observation)?;

// Step 3: Get beliefs at each level
let beliefs = model.get_all_beliefs();
// beliefs[0] = low-level (sensor fusion)
// beliefs[1] = mid-level (feature extraction)
// beliefs[2] = high-level (goal inference)
```

**Best For**:
- PWSA: Multi-level threat assessment
- Robotics: Sensor ‚Üí feature ‚Üí goal hierarchy
- LLM: Token ‚Üí sentence ‚Üí paragraph ‚Üí document hierarchy

---

### Pattern 5: Combined Pipeline

**Use Case**: Full integration of multiple Worker 1 modules

```rust
use prism_ai::{
    detect_causal_direction,
    TimeSeriesForecaster, LstmConfig, CellType,
    ThermodynamicNetwork, NetworkConfig,
    HierarchicalModel, StateSpaceLevel,
};

// Step 1: Detect causality
let coupling = detect_causal_direction(&x, &y, 2, 1, 5)?;

if coupling.te_x_to_y > 0.5 {
    // Step 2: Forecast dependent variable
    let mut forecaster = TimeSeriesForecaster::new();
    let lstm_config = LstmConfig {
        cell_type: CellType::LSTM,
        hidden_size: 20,
        sequence_length: 10,
        ..Default::default()
    };

    forecaster.fit_lstm(&y, lstm_config)?;
    let forecast = forecaster.forecast_lstm(&y, 10)?;

    // Step 3: Use thermodynamic consensus for actions
    let config = NetworkConfig { num_nodes: 3, ..Default::default() };
    let mut network = ThermodynamicNetwork::new(config);

    for pred in forecast {
        // Step 4: Hierarchical inference for final decision
        let mut hier_model = HierarchicalModel::new(levels);
        hier_model.infer_states(&vec![pred])?;

        // Combine beliefs with thermodynamic state
        network.step()?;
        let state = network.get_state();

        println!("Prediction: {:.2}, Free Energy: {:.4}", pred, state.free_energy);
    }
}
```

**Best For**:
- Complex decision pipelines
- Multi-stage reasoning
- Full system integration tests

---

### Pattern 6: High-Accuracy TE with KSG Estimator (Phase 1)

**Use Case**: More accurate causal detection with reduced bias

```rust
use prism_ai::{KsgEstimator, ConditionalTe, BootstrapResampler, BootstrapMethod};

// Step 1: Use KSG instead of histogram-based TE (50-80% bias reduction)
let ksg = KsgEstimator::new(
    k: 5,              // k-neighbors
    source_embedding: 3,
    target_embedding: 2,
    time_lag: 1
);

let result = ksg.calculate(&source, &target)?;
println!("TE (KSG): {:.4} bits", result.te_value);

// Step 2: Control for confounders with Conditional TE
let cte = ConditionalTe::new(5, 3, 2, 2, 1);
let cte_result = cte.calculate(&source, &target, &confounder)?;
println!("Conditional TE(X‚ÜíY|Z): {:.4} bits", cte_result.te_value);

// Step 3: Add rigorous uncertainty quantification
let resampler = BootstrapResampler::new(1000, 0.95, 10, BootstrapMethod::Bca);
let ci = resampler.resample(|src, tgt| {
    let ksg = KsgEstimator::new(5, 3, 2, 1);
    ksg.calculate(src, tgt).map(|r| r.te_value)
}, &source, &target)?;

println!("TE = {:.4} [{:.4}, {:.4}] @ 95% CI", ci.observed, ci.lower, ci.upper);
```

**Best For**:
- PWSA: High-accuracy missile coupling detection
- LLM: Precise model interaction measurement
- Robotics: Multi-agent coordination analysis
- Any application requiring statistical rigor

---

### Pattern 7: Real-Time Streaming TE (Phase 2)

**Use Case**: Monitor causal relationships in real-time data streams

```rust
use prism_ai::IncrementalTe;

// Step 1: Initialize with historical data
let mut inc_te = IncrementalTe::new(
    source_embedding: 3,
    target_embedding: 2,
    time_lag: 1,
    n_bins: 10,
    window_size: Some(100)  // Sliding window
);

inc_te.init(&historical_source, &historical_target)?;

// Step 2: Stream new data points with O(1) updates
for (new_source, new_target) in real_time_stream {
    inc_te.update(new_source, new_target)?;
    let current_te = inc_te.calculate()?;

    // Detect regime changes
    if current_te > threshold {
        println!("Alert: Coupling strength increased to {:.3}", current_te);
    }
}
```

**Best For**:
- PWSA: Real-time threat coupling monitoring
- LLM: Live model interaction tracking
- Robotics: Dynamic multi-agent coordination
- Any streaming data application (10-50x faster than batch recomputation)

---

### Pattern 8: Adaptive Parameter Selection (Phase 2)

**Use Case**: Automatic optimal embedding parameter selection

```rust
use prism_ai::{AdaptiveEmbedding, SymbolicTe};

// Step 1: Automatically determine optimal parameters
let adaptive = AdaptiveEmbedding::new(
    max_dimension: 10,
    max_delay: 20,
    tolerance: 0.01
);

let params = adaptive.select_embedding(&time_series)?;
println!("Optimal embedding: dim={}, delay={}", params.dimension, params.delay);

// Step 2: Use optimal parameters for TE calculation
let ksg = KsgEstimator::new(5, params.dimension, params.dimension, params.delay);
let result = ksg.calculate(&source, &target)?;

// Step 3: For noisy data, use Symbolic TE (noise-robust)
let ste = SymbolicTe::new(
    pattern_length: 4,  // Ordinal pattern length
    pattern_delay: 1,
    te_lag: params.delay
);

let symbolic_result = ste.calculate(&noisy_source, &noisy_target)?;
println!("Symbolic TE (noise-robust): {:.4} bits", symbolic_result.te_value);
```

**Best For**:
- Noisy sensor data (works with 50%+ noise)
- Short time series (<100 points)
- Unknown optimal parameters
- Adaptive systems that need automatic tuning

---

### Pattern 9: Multivariate Information Decomposition (Phase 3)

**Use Case**: Understand unique vs redundant information from multiple predictors

```rust
use prism_ai::{PartialInfoDecomp, PidMethod};

// Scenario: Two models (X1, X2) predicting target Y
// Question: How much unique information does each provide?

let pid = PartialInfoDecomp::new(10, PidMethod::MinMi);
let result = pid.calculate(&model1_predictions, &model2_predictions, &actual_target)?;

println!("Information Decomposition:");
println!("  Total MI:      {:.4} bits", result.total_mi);
println!("  Unique(M1):    {:.4} bits", result.unique_x1);
println!("  Unique(M2):    {:.4} bits", result.unique_x2);
println!("  Redundant:     {:.4} bits", result.redundant);
println!("  Synergy:       {:.4} bits", result.synergy);

// Interpret results
if result.unique_x1 > result.unique_x2 {
    println!("Model 1 provides more unique information");
} else if result.synergy > result.redundant {
    println!("Models work synergistically - ensemble recommended");
} else {
    println!("Models provide redundant information - single model sufficient");
}
```

**Best For**:
- LLM: Multi-model ensemble analysis
- Feature selection (which features are truly unique?)
- Sensor fusion (which sensors provide non-redundant information?)
- Understanding multi-predictor systems

---

### Pattern 10: Multiple Testing Correction for Network Analysis (Phase 3)

**Use Case**: Test many causal relationships while controlling false discoveries

```rust
use prism_ai::{KsgEstimator, MultipleTestingCorrection, CorrectionMethod};

// Scenario: Test TE across N√óN variable pairs
let n_vars = 20;
let mut p_values = Vec::new();
let mut te_matrix = vec![vec![0.0; n_vars]; n_vars];

// Step 1: Compute TE for all pairs
for i in 0..n_vars {
    for j in 0..n_vars {
        if i != j {
            let ksg = KsgEstimator::new(5, 3, 2, 1);
            let result = ksg.calculate(&data[i], &data[j])?;
            te_matrix[i][j] = result.te_value;
            p_values.push(result.p_value);
        }
    }
}

// Step 2: Apply FDR correction (controls false discovery rate)
let corrector = MultipleTestingCorrection::new(0.05, CorrectionMethod::BenjaminiHochberg);
let corrected = corrector.correct(&p_values)?;

println!("Discoveries: {} out of {} tests", corrected.n_discoveries(), p_values.len());
println!("Discovery rate: {:.1}%", corrected.discovery_rate() * 100.0);

// Step 3: Extract significant edges
let discovery_indices = corrected.discovery_indices();
for &idx in &discovery_indices {
    let i = idx / (n_vars - 1);
    let j = idx % (n_vars - 1);
    println!("Significant edge: {} ‚Üí {} (TE={:.4})", i, j, te_matrix[i][j]);
}
```

**Best For**:
- Network discovery (finding true causal edges)
- Multi-lag analysis (testing many time lags)
- Feature selection with many candidates
- Any scenario with multiple hypothesis tests

---

## Domain-Specific Integration

### Worker 3 (PWSA) - Trajectory Forecasting

**Objective**: Predict missile trajectories for intercept planning

**Integration Code**:

```rust
use prism_ai::{TimeSeriesForecaster, ArimaConfig};

pub fn predict_threat_trajectory(
    historical_tracks: &[Vec<f64>],  // [x, y, z] positions over time
    horizon_seconds: usize,
) -> Result<Vec<Vec<f64>>> {
    let mut forecaster = TimeSeriesForecaster::new();

    let arima_config = ArimaConfig {
        p: 3,  // High AR order for smooth trajectories
        d: 1,  // First-order differencing
        q: 2,  // MA for noise reduction
        include_constant: false,  // Ballistic motion has no drift
    };

    let mut forecasts = Vec::new();

    // Forecast each dimension separately
    for dimension in 0..3 {  // x, y, z
        let dim_data: Vec<f64> = historical_tracks.iter()
            .map(|track| track[dimension])
            .collect();

        forecaster.fit_arima(&dim_data, arima_config)?;
        let forecast = forecaster.forecast_arima(horizon_seconds)?;
        forecasts.push(forecast);
    }

    Ok(forecasts)
}
```

**Testing**:
```bash
cargo test --lib pwsa::trajectory_prediction --features cuda
```

**Success Criteria**:
- Trajectory RMSE < 5% at T+5s
- Forecast time < 50ms
- Integration with existing PWSA systems

---

### Worker 5 (LLM) - Cost Forecasting & Thermodynamic Routing

**Objective**: Predict LLM costs and optimize model selection proactively

**Integration Code**:

```rust
use prism_ai::{
    TimeSeriesForecaster, LstmConfig, CellType,
    ThermodynamicNetwork, NetworkConfig
};

pub fn proactive_llm_optimization(
    historical_costs: &[f64],
    horizon_days: usize,
) -> Result<ModelSelectionStrategy> {
    // Step 1: Forecast costs
    let mut forecaster = TimeSeriesForecaster::new();

    let lstm_config = LstmConfig {
        cell_type: CellType::GRU,  // GRU faster for time series
        hidden_size: 30,
        sequence_length: 14,  // 2 weeks lookback
        epochs: 50,
        ..Default::default()
    };

    forecaster.fit_lstm(historical_costs, lstm_config)?;
    let cost_forecast = forecaster.forecast_lstm(historical_costs, horizon_days)?;

    // Step 2: Adjust thermodynamic parameters
    let config = NetworkConfig {
        num_nodes: 6,  // 6 LLM models
        coupling_strength: 1.0,
        temperature: 1.0,
        dt: 0.01,
        dissipation: 0.1,
    };

    let mut network = ThermodynamicNetwork::new(config);

    // Step 3: Adaptive temperature based on forecast
    for (day, predicted_cost) in cost_forecast.iter().enumerate() {
        if predicted_cost > &high_cost_threshold {
            // High cost predicted ‚Üí increase temperature ‚Üí more exploration
            network.set_temperature(1.5);
            println!("Day {}: High cost, exploring cheaper models", day);
        } else {
            // Normal cost ‚Üí decrease temperature ‚Üí exploit best models
            network.set_temperature(0.5);
            println!("Day {}: Normal cost, exploiting best models", day);
        }

        network.step()?;
    }

    let final_state = network.get_state();

    Ok(ModelSelectionStrategy {
        cost_forecast,
        temperature_schedule: final_state.temperature,
        recommended_models: extract_top_models(&network),
    })
}
```

**Testing**:
```bash
cargo test --lib llm::cost_forecasting --features cuda
```

**Success Criteria**:
- Cost forecast accuracy within 10%
- 40-70% cost reduction vs baseline
- <10ms routing decisions

---

### Worker 7 (Robotics) - Environment Dynamics Prediction

**Objective**: Predict obstacle motion and plan safe trajectories

**Integration Code**:

```rust
use prism_ai::{
    TimeSeriesForecaster, LstmConfig, CellType,
    HierarchicalModel, StateSpaceLevel, PolicySelector
};

pub fn plan_with_environment_prediction(
    obstacle_history: &[Vec<f64>],  // Historical obstacle positions
    robot_state: &[f64],
    goal: &[f64],
    horizon_seconds: usize,
) -> Result<MotionPlan> {
    // Step 1: Predict obstacle motion
    let mut forecaster = TimeSeriesForecaster::new();

    let lstm_config = LstmConfig {
        cell_type: CellType::LSTM,
        hidden_size: 40,
        sequence_length: 20,  // 2 seconds @ 10Hz
        epochs: 30,
        ..Default::default()
    };

    let mut obstacle_forecasts = Vec::new();

    for obstacle in obstacle_history {
        forecaster.fit_lstm(obstacle, lstm_config)?;
        let forecast = forecaster.forecast_lstm(obstacle, horizon_seconds)?;
        obstacle_forecasts.push(forecast);
    }

    // Step 2: Hierarchical motion planning
    let levels = vec![
        StateSpaceLevel {
            state_dim: 6,      // Position + velocity
            obs_dim: 3,        // Position sensors
            precision: 1.0,
            learning_rate: 0.01,
            timescale: 0.1,    // 100ms (sensor level)
        },
        StateSpaceLevel {
            state_dim: 12,     // Trajectory features
            obs_dim: 6,
            precision: 0.5,
            learning_rate: 0.005,
            timescale: 1.0,    // 1s (trajectory level)
        },
        StateSpaceLevel {
            state_dim: 24,     // Goal-level planning
            obs_dim: 12,
            precision: 0.1,
            learning_rate: 0.001,
            timescale: 10.0,   // 10s (strategic level)
        },
    ];

    let mut hier_model = HierarchicalModel::new(levels);
    let policy_selector = PolicySelector::new(0.1);

    // Step 3: Plan path avoiding predicted obstacles
    let mut waypoints = Vec::new();

    for t in 0..horizon_seconds {
        // Get predicted obstacle positions at time t
        let obstacles_at_t: Vec<f64> = obstacle_forecasts.iter()
            .map(|forecast| forecast[t])
            .collect();

        // Hierarchical inference
        let observation = create_observation(robot_state, &obstacles_at_t, goal);
        hier_model.infer_states(&observation)?;

        // Select action
        let action = policy_selector.select_action(
            &gen_model,
            &var_inference,
            &observation,
            robot_state
        )?;

        waypoints.push(action);
    }

    Ok(MotionPlan { waypoints, safety_margin: 0.5 })
}
```

**Testing**:
```bash
cargo test --lib robotics::motion_planning --features cuda
```

**Success Criteria**:
- Collision avoidance: >99.5%
- Path efficiency: >90% of optimal
- Planning time: <100ms

---

## Conflict Resolution

### If Build Fails After Merge

**Issue**: Compilation errors after merging Worker 1

**Resolution**:
1. Check Cargo.toml has correct dependencies:
   ```toml
   [dependencies]
   ndarray = "0.15"
   rand = "0.8"
   anyhow = "1.0"
   ```

2. Verify feature flags:
   ```bash
   cargo build --lib --features cuda
   ```

3. Check import paths:
   ```rust
   use prism_ai::time_series::TimeSeriesForecaster;  // ‚ùå Wrong
   use prism_ai::TimeSeriesForecaster;  // ‚úÖ Correct (exported in lib.rs)
   ```

4. If still failing, check Worker 1 deliverables:
   ```bash
   git log origin/worker-1-ai-core --oneline -5
   ```

---

### If Tests Fail

**Issue**: Worker 1's tests fail in your environment

**Resolution**:
1. Check GPU availability:
   ```rust
   let gpu_available = crate::gpu::kernel_executor::get_global_executor().is_ok();
   println!("GPU available: {}", gpu_available);
   ```

2. Run tests with verbose output:
   ```bash
   cargo test --lib time_series -- --nocapture
   ```

3. Verify CPU fallback works:
   - All Worker 1 modules have CPU implementations
   - GPU unavailable = performance degradation, not failure

4. If specific test fails:
   ```bash
   cargo test --lib time_series::test_lstm_forecast -- --exact --nocapture
   ```

---

### If Performance Suboptimal

**Issue**: Worker 1 modules slower than expected

**Resolution**:
1. Check GPU usage:
   ```bash
   nvidia-smi  # Should show GPU utilization
   ```

2. Verify GPU kernels loaded:
   - Worker 2 provides GPU kernels
   - Without kernels: CPU fallback (5-10x slower)
   - Expected: <100ms TE, <10ms forecasts
   - CPU-only: ~500-1000ms TE, ~50-100ms forecasts

3. Optimize hyperparameters:
   - Reduce sequence_length for faster LSTM training
   - Reduce epochs for faster convergence
   - Reduce k_neighbors for faster TE

4. Profile performance:
   ```bash
   cargo build --release --features cuda
   cargo bench --features cuda
   ```

---

## Communication Protocol

### Requesting Help from Worker 1

**Format**:
```
Subject: [WORKER-1] Integration Issue: <Brief Description>

Worker: <Your worker number>
Module: <Which Worker 1 module>
Issue: <Describe the problem>
Expected: <What you expected>
Actual: <What happened>
Code: <Minimal reproduction case>
Logs: <Relevant error messages>
```

**Example**:
```
Subject: [WORKER-1] Integration Issue: TimeSeriesForecaster import error

Worker: 3
Module: time_series
Issue: Cannot import TimeSeriesForecaster
Expected: Import should work from prism_ai::TimeSeriesForecaster
Actual: Compiler error "unresolved import"
Code:
  use prism_ai::TimeSeriesForecaster;
  let forecaster = TimeSeriesForecaster::new();
Logs:
  error[E0432]: unresolved import `prism_ai::TimeSeriesForecaster`
```

---

### Reporting Integration Success

When integration complete, update:

**1. Your DAILY_PROGRESS.md**:
```markdown
### Worker 1 Integration Complete ‚úÖ

- [x] Merged worker-1-ai-core branch
- [x] Build successful
- [x] Time Series integrated into PWSA
- [x] Trajectory prediction working
- [x] Tests passing (15/15)
- [x] Performance validated (<50ms forecasts)
```

**2. Tag Worker 1 in commit**:
```bash
git commit -m "feat: integrate Worker 1 time series for trajectory prediction

- Merged worker-1-ai-core (commit d9ad504)
- Integrated TimeSeriesForecaster with PWSA
- Trajectory forecasting: <50ms, RMSE <3%
- Tests: 15 new integration tests passing

Integration-With: Worker-1
Closes: #<issue_number>"
```

---

## Integration Checklist

### Pre-Integration ‚úÖ

- [x] Worker 1 deliverables published
- [x] Worker 1 tests passing
- [x] Documentation complete
- [x] Integration examples provided

### Worker 3 Integration ‚è≥

- [ ] Merge worker-1-ai-core
- [ ] Build successful
- [ ] Import time series module
- [ ] Trajectory prediction implemented
- [ ] PWSA integration tests pass
- [ ] Performance validated
- [ ] Documentation updated

### Worker 5 Integration ‚è≥

- [ ] Merge worker-1-ai-core
- [ ] Build successful
- [ ] Import thermodynamic + time series
- [ ] Cost forecasting implemented
- [ ] Proactive model selection working
- [ ] 40-70% cost savings measured
- [ ] Documentation updated

### Worker 7 Integration ‚è≥

- [ ] Merge worker-1-ai-core
- [ ] Build successful
- [ ] Import time series + active inference
- [ ] Environment prediction implemented
- [ ] Motion planning with forecasts working
- [ ] Safety improvements validated
- [ ] Documentation updated

### Post-Integration Testing ‚úÖ

- [ ] Cross-worker integration tests
- [ ] End-to-end pipeline tests
- [ ] Performance benchmarking
- [ ] GPU acceleration validated (if Worker 2 ready)
- [ ] Production readiness assessment

---

## Timeline & Milestones

**Week 5 Milestones**:

| Day | Milestone | Owner | Status |
|-----|-----------|-------|--------|
| Mon | Worker 1 deliverables published | Worker 1 | ‚úÖ |
| Tue | Worker 3 integration started | Worker 3 | ‚è≥ |
| Tue | Worker 5 integration started | Worker 5 | ‚è≥ |
| Tue | Worker 7 integration started | Worker 7 | ‚è≥ |
| Wed | Integration 50% complete | All | ‚è≥ |
| Thu | Integration 90% complete | All | ‚è≥ |
| Fri | Integration testing complete | All | ‚è≥ |
| Fri | Week 5 deliverables merged | All | ‚è≥ |

---

**Worker 1 Integration Protocol**: üìã **ACTIVE**

All dependent workers may proceed with integration immediately.
