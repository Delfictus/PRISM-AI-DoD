//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-35583870
// Cuda compilation tools, release 12.8, V12.8.93
// Based on NVVM 7.0.1
//

.version 8.7
.target sm_90
.address_size 64

	// .globl	schmidt_svd_kernel
// _ZZ18schmidt_svd_kernelE8A_shared has been demoted
.extern .shared .align 16 .b8 partial_sums[];

.visible .entry schmidt_svd_kernel(
	.param .u64 schmidt_svd_kernel_param_0,
	.param .u64 schmidt_svd_kernel_param_1,
	.param .u32 schmidt_svd_kernel_param_2,
	.param .u32 schmidt_svd_kernel_param_3,
	.param .u32 schmidt_svd_kernel_param_4
)
{
	.reg .pred 	%p<8>;
	.reg .f32 	%f<27>;
	.reg .b32 	%r<45>;
	.reg .b64 	%rd<9>;
	// demoted variable
	.shared .align 4 .b8 _ZZ18schmidt_svd_kernelE8A_shared[1024];

	ld.param.u64 	%rd1, [schmidt_svd_kernel_param_0];
	ld.param.u64 	%rd2, [schmidt_svd_kernel_param_1];
	ld.param.u32 	%r19, [schmidt_svd_kernel_param_2];
	ld.param.u32 	%r20, [schmidt_svd_kernel_param_3];
	mov.u32 	%r21, %ntid.x;
	mov.u32 	%r22, %ctaid.x;
	mov.u32 	%r23, %tid.x;
	mad.lo.s32 	%r1, %r22, %r21, %r23;
	mul.lo.s32 	%r24, %r20, %r19;
	setp.ge.s32 	%p1, %r1, %r24;
	@%p1 bra 	$L__BB0_2;

	cvta.to.global.u64 	%rd3, %rd1;
	mul.wide.s32 	%rd4, %r1, 4;
	add.s64 	%rd5, %rd3, %rd4;
	ld.global.f32 	%f8, [%rd5];
	shl.b32 	%r25, %r1, 2;
	mov.u32 	%r26, _ZZ18schmidt_svd_kernelE8A_shared;
	add.s32 	%r27, %r26, %r25;
	st.shared.f32 	[%r27], %f8;

$L__BB0_2:
	bar.sync 	0;
	setp.ge.s32 	%p2, %r1, %r20;
	@%p2 bra 	$L__BB0_11;

	setp.lt.s32 	%p3, %r19, 1;
	mov.f32 	%f26, 0f00000000;
	@%p3 bra 	$L__BB0_10;

	add.s32 	%r29, %r19, -1;
	and.b32  	%r44, %r19, 3;
	setp.lt.u32 	%p4, %r29, 3;
	mov.f32 	%f26, 0f00000000;
	mov.u32 	%r42, 0;
	@%p4 bra 	$L__BB0_7;

	sub.s32 	%r41, %r19, %r44;
	shl.b32 	%r31, %r1, 2;
	mov.u32 	%r32, _ZZ18schmidt_svd_kernelE8A_shared;
	add.s32 	%r39, %r32, %r31;
	shl.b32 	%r5, %r20, 2;
	mov.f32 	%f26, 0f00000000;
	mov.u32 	%r42, 0;

$L__BB0_6:
	ld.shared.f32 	%f13, [%r39];
	fma.rn.f32 	%f14, %f13, %f13, %f26;
	add.s32 	%r33, %r39, %r5;
	ld.shared.f32 	%f15, [%r33];
	fma.rn.f32 	%f16, %f15, %f15, %f14;
	add.s32 	%r34, %r33, %r5;
	ld.shared.f32 	%f17, [%r34];
	fma.rn.f32 	%f18, %f17, %f17, %f16;
	add.s32 	%r35, %r34, %r5;
	add.s32 	%r39, %r35, %r5;
	ld.shared.f32 	%f19, [%r35];
	fma.rn.f32 	%f26, %f19, %f19, %f18;
	add.s32 	%r42, %r42, 4;
	add.s32 	%r41, %r41, -4;
	setp.ne.s32 	%p5, %r41, 0;
	@%p5 bra 	$L__BB0_6;

$L__BB0_7:
	setp.eq.s32 	%p6, %r44, 0;
	@%p6 bra 	$L__BB0_10;

	mad.lo.s32 	%r36, %r42, %r20, %r1;
	shl.b32 	%r37, %r36, 2;
	mov.u32 	%r38, _ZZ18schmidt_svd_kernelE8A_shared;
	add.s32 	%r43, %r38, %r37;
	shl.b32 	%r14, %r20, 2;

$L__BB0_9:
	.pragma "nounroll";
	ld.shared.f32 	%f20, [%r43];
	fma.rn.f32 	%f26, %f20, %f20, %f26;
	add.s32 	%r43, %r43, %r14;
	add.s32 	%r44, %r44, -1;
	setp.ne.s32 	%p7, %r44, 0;
	@%p7 bra 	$L__BB0_9;

$L__BB0_10:
	cvta.to.global.u64 	%rd6, %rd2;
	mul.wide.s32 	%rd7, %r1, 4;
	add.s64 	%rd8, %rd6, %rd7;
	sqrt.rn.f32 	%f21, %f26;
	st.global.f32 	[%rd8], %f21;

$L__BB0_11:
	ret;

}
	// .globl	entanglement_entropy_kernel
.visible .entry entanglement_entropy_kernel(
	.param .u64 entanglement_entropy_kernel_param_0,
	.param .u64 entanglement_entropy_kernel_param_1,
	.param .u32 entanglement_entropy_kernel_param_2
)
{
	.reg .pred 	%p<10>;
	.reg .f32 	%f<48>;
	.reg .b32 	%r<19>;
	.reg .b64 	%rd<7>;


	ld.param.u64 	%rd1, [entanglement_entropy_kernel_param_0];
	ld.param.u64 	%rd2, [entanglement_entropy_kernel_param_1];
	ld.param.u32 	%r8, [entanglement_entropy_kernel_param_2];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r9, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	mad.lo.s32 	%r3, %r9, %r1, %r2;
	setp.ge.s32 	%p1, %r3, %r8;
	mov.f32 	%f47, 0f00000000;
	@%p1 bra 	$L__BB1_5;

	cvta.to.global.u64 	%rd3, %rd1;
	mul.wide.s32 	%rd4, %r3, 4;
	add.s64 	%rd5, %rd3, %rd4;
	ld.global.f32 	%f1, [%rd5];
	setp.leu.f32 	%p2, %f1, 0f2EDBE6FF;
	@%p2 bra 	$L__BB1_5;

	setp.lt.f32 	%p3, %f1, 0f00800000;
	mul.f32 	%f10, %f1, 0f4B000000;
	selp.f32 	%f2, %f10, %f1, %p3;
	selp.f32 	%f11, 0fC1B80000, 0f00000000, %p3;
	mov.b32 	%r10, %f2;
	add.s32 	%r11, %r10, -1059760811;
	and.b32  	%r12, %r11, -8388608;
	sub.s32 	%r13, %r10, %r12;
	mov.b32 	%f12, %r13;
	cvt.rn.f32.s32 	%f13, %r12;
	mov.f32 	%f14, 0f34000000;
	fma.rn.f32 	%f15, %f13, %f14, %f11;
	add.f32 	%f16, %f12, 0fBF800000;
	mov.f32 	%f17, 0f3E1039F6;
	mov.f32 	%f18, 0fBE055027;
	fma.rn.f32 	%f19, %f18, %f16, %f17;
	mov.f32 	%f20, 0fBDF8CDCC;
	fma.rn.f32 	%f21, %f19, %f16, %f20;
	mov.f32 	%f22, 0f3E0F2955;
	fma.rn.f32 	%f23, %f21, %f16, %f22;
	mov.f32 	%f24, 0fBE2AD8B9;
	fma.rn.f32 	%f25, %f23, %f16, %f24;
	mov.f32 	%f26, 0f3E4CED0B;
	fma.rn.f32 	%f27, %f25, %f16, %f26;
	mov.f32 	%f28, 0fBE7FFF22;
	fma.rn.f32 	%f29, %f27, %f16, %f28;
	mov.f32 	%f30, 0f3EAAAA78;
	fma.rn.f32 	%f31, %f29, %f16, %f30;
	mov.f32 	%f32, 0fBF000000;
	fma.rn.f32 	%f33, %f31, %f16, %f32;
	mul.f32 	%f34, %f16, %f33;
	fma.rn.f32 	%f35, %f34, %f16, %f16;
	mov.f32 	%f36, 0f3F317218;
	fma.rn.f32 	%f46, %f15, %f36, %f35;
	setp.lt.u32 	%p4, %r10, 2139095040;
	@%p4 bra 	$L__BB1_4;

	mov.f32 	%f37, 0f7F800000;
	fma.rn.f32 	%f46, %f2, %f37, %f37;

$L__BB1_4:
	setp.eq.f32 	%p5, %f2, 0f00000000;
	selp.f32 	%f38, 0fFF800000, %f46, %p5;
	mul.f32 	%f39, %f1, %f38;
	neg.f32 	%f47, %f39;

$L__BB1_5:
	shl.b32 	%r14, %r2, 2;
	mov.u32 	%r15, partial_sums;
	add.s32 	%r4, %r15, %r14;
	st.shared.f32 	[%r4], %f47;
	bar.sync 	0;
	shr.u32 	%r18, %r1, 1;
	setp.eq.s32 	%p6, %r18, 0;
	@%p6 bra 	$L__BB1_9;

$L__BB1_6:
	setp.ge.s32 	%p7, %r2, %r18;
	@%p7 bra 	$L__BB1_8;

	shl.b32 	%r16, %r18, 2;
	add.s32 	%r17, %r4, %r16;
	ld.shared.f32 	%f40, [%r4];
	ld.shared.f32 	%f41, [%r17];
	add.f32 	%f42, %f41, %f40;
	st.shared.f32 	[%r4], %f42;

$L__BB1_8:
	bar.sync 	0;
	shr.u32 	%r18, %r18, 1;
	setp.ne.s32 	%p8, %r18, 0;
	@%p8 bra 	$L__BB1_6;

$L__BB1_9:
	setp.ne.s32 	%p9, %r2, 0;
	@%p9 bra 	$L__BB1_11;

	ld.shared.f32 	%f43, [partial_sums];
	cvta.to.global.u64 	%rd6, %rd2;
	atom.global.add.f32 	%f44, [%rd6], %f43;

$L__BB1_11:
	ret;

}
	// .globl	partial_transpose_kernel
.visible .entry partial_transpose_kernel(
	.param .u64 partial_transpose_kernel_param_0,
	.param .u64 partial_transpose_kernel_param_1,
	.param .u32 partial_transpose_kernel_param_2,
	.param .u32 partial_transpose_kernel_param_3
)
{
	.reg .pred 	%p<4>;
	.reg .f32 	%f<2>;
	.reg .b32 	%r<20>;
	.reg .b64 	%rd<9>;


	ld.param.u64 	%rd1, [partial_transpose_kernel_param_0];
	ld.param.u64 	%rd2, [partial_transpose_kernel_param_1];
	ld.param.u32 	%r5, [partial_transpose_kernel_param_2];
	ld.param.u32 	%r4, [partial_transpose_kernel_param_3];
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r8, %tid.x;
	mad.lo.s32 	%r1, %r6, %r7, %r8;
	mov.u32 	%r9, %ntid.y;
	mov.u32 	%r10, %ctaid.y;
	mov.u32 	%r11, %tid.y;
	mad.lo.s32 	%r2, %r10, %r9, %r11;
	mul.lo.s32 	%r3, %r4, %r5;
	setp.ge.s32 	%p1, %r1, %r3;
	setp.ge.s32 	%p2, %r2, %r3;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	$L__BB2_2;

	cvta.to.global.u64 	%rd3, %rd1;
	rem.s32 	%r12, %r1, %r4;
	sub.s32 	%r13, %r1, %r12;
	rem.s32 	%r14, %r2, %r4;
	add.s32 	%r15, %r13, %r14;
	mad.lo.s32 	%r16, %r3, %r1, %r2;
	mul.wide.s32 	%rd4, %r16, 4;
	add.s64 	%rd5, %rd3, %rd4;
	ld.global.f32 	%f1, [%rd5];
	add.s32 	%r17, %r12, %r2;
	sub.s32 	%r18, %r17, %r14;
	mad.lo.s32 	%r19, %r15, %r3, %r18;
	cvta.to.global.u64 	%rd6, %rd2;
	mul.wide.s32 	%rd7, %r19, 4;
	add.s64 	%rd8, %rd6, %rd7;
	st.global.f32 	[%rd8], %f1;

$L__BB2_2:
	ret;

}
	// .globl	three_tangle_kernel
.visible .entry three_tangle_kernel(
	.param .u64 three_tangle_kernel_param_0,
	.param .u64 three_tangle_kernel_param_1,
	.param .u32 three_tangle_kernel_param_2
)
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<7>;
	.reg .b64 	%rd<3>;


	ld.param.u64 	%rd1, [three_tangle_kernel_param_1];
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mul.lo.s32 	%r3, %r1, %r2;
	mov.u32 	%r4, %tid.x;
	neg.s32 	%r5, %r4;
	setp.ne.s32 	%p1, %r3, %r5;
	@%p1 bra 	$L__BB3_2;

	cvta.to.global.u64 	%rd2, %rd1;
	mov.u32 	%r6, 1018712552;
	st.global.u32 	[%rd2], %r6;

$L__BB3_2:
	ret;

}
	// .globl	mps_contraction_kernel
.visible .entry mps_contraction_kernel(
	.param .u64 mps_contraction_kernel_param_0,
	.param .u64 mps_contraction_kernel_param_1,
	.param .u64 mps_contraction_kernel_param_2,
	.param .u32 mps_contraction_kernel_param_3,
	.param .u32 mps_contraction_kernel_param_4,
	.param .u32 mps_contraction_kernel_param_5
)
{
	.reg .pred 	%p<9>;
	.reg .f32 	%f<58>;
	.reg .b32 	%r<59>;
	.reg .b64 	%rd<42>;


	ld.param.u64 	%rd15, [mps_contraction_kernel_param_0];
	ld.param.u64 	%rd16, [mps_contraction_kernel_param_1];
	ld.param.u64 	%rd14, [mps_contraction_kernel_param_2];
	ld.param.u32 	%r24, [mps_contraction_kernel_param_3];
	ld.param.u32 	%r22, [mps_contraction_kernel_param_4];
	ld.param.u32 	%r23, [mps_contraction_kernel_param_5];
	cvta.to.global.u64 	%rd1, %rd16;
	cvta.to.global.u64 	%rd2, %rd15;
	mov.u32 	%r25, %ntid.x;
	mov.u32 	%r26, %ctaid.x;
	mov.u32 	%r27, %tid.x;
	mad.lo.s32 	%r1, %r26, %r25, %r27;
	mov.u32 	%r28, %ntid.y;
	mov.u32 	%r29, %ctaid.y;
	mul.lo.s32 	%r2, %r29, %r28;
	mov.u32 	%r3, %tid.y;
	add.s32 	%r4, %r2, %r3;
	setp.ge.s32 	%p1, %r1, %r24;
	setp.ge.s32 	%p2, %r4, %r23;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	$L__BB4_9;

	setp.lt.s32 	%p4, %r22, 1;
	mov.f32 	%f56, 0f00000000;
	mov.f32 	%f57, %f56;
	@%p4 bra 	$L__BB4_8;

	add.s32 	%r31, %r22, -1;
	and.b32  	%r58, %r22, 3;
	setp.lt.u32 	%p5, %r31, 3;
	mov.f32 	%f57, 0f00000000;
	mov.u32 	%r55, 0;
	mov.f32 	%f56, %f57;
	@%p5 bra 	$L__BB4_5;

	shl.b32 	%r33, %r1, 1;
	or.b32  	%r34, %r33, 1;
	mul.lo.s32 	%r35, %r22, %r34;
	mul.lo.s32 	%r36, %r22, %r1;
	shl.b32 	%r37, %r36, 1;
	mul.wide.s32 	%rd3, %r35, 4;
	mul.wide.s32 	%rd4, %r37, 4;
	shl.b32 	%r6, %r23, 3;
	sub.s32 	%r7, %r58, %r22;
	mul.wide.s32 	%rd5, %r23, 4;
	mov.f32 	%f57, 0f00000000;
	mov.u32 	%r55, 0;
	mov.u32 	%r53, %r4;
	mov.u64 	%rd39, %rd2;

$L__BB4_4:
	add.s64 	%rd17, %rd39, %rd4;
	mul.wide.s32 	%rd18, %r53, 4;
	add.s64 	%rd19, %rd1, %rd18;
	ld.global.f32 	%f22, [%rd19];
	ld.global.f32 	%f23, [%rd17];
	fma.rn.f32 	%f24, %f23, %f22, %f56;
	add.s64 	%rd20, %rd39, %rd3;
	add.s64 	%rd21, %rd19, %rd5;
	ld.global.f32 	%f25, [%rd21];
	ld.global.f32 	%f26, [%rd20];
	fma.rn.f32 	%f27, %f26, %f25, %f57;
	add.s64 	%rd22, %rd21, %rd5;
	ld.global.f32 	%f28, [%rd22];
	ld.global.f32 	%f29, [%rd17+4];
	fma.rn.f32 	%f30, %f29, %f28, %f24;
	add.s64 	%rd23, %rd22, %rd5;
	ld.global.f32 	%f31, [%rd23];
	ld.global.f32 	%f32, [%rd20+4];
	fma.rn.f32 	%f33, %f32, %f31, %f27;
	add.s64 	%rd24, %rd23, %rd5;
	ld.global.f32 	%f34, [%rd24];
	ld.global.f32 	%f35, [%rd17+8];
	fma.rn.f32 	%f36, %f35, %f34, %f30;
	add.s64 	%rd25, %rd24, %rd5;
	ld.global.f32 	%f37, [%rd25];
	ld.global.f32 	%f38, [%rd20+8];
	fma.rn.f32 	%f39, %f38, %f37, %f33;
	add.s64 	%rd26, %rd25, %rd5;
	ld.global.f32 	%f40, [%rd26];
	ld.global.f32 	%f41, [%rd17+12];
	fma.rn.f32 	%f56, %f41, %f40, %f36;
	add.s64 	%rd27, %rd26, %rd5;
	ld.global.f32 	%f42, [%rd27];
	ld.global.f32 	%f43, [%rd20+12];
	fma.rn.f32 	%f57, %f43, %f42, %f39;
	add.s64 	%rd39, %rd39, 16;
	add.s32 	%r53, %r53, %r6;
	add.s32 	%r55, %r55, 4;
	add.s32 	%r38, %r7, %r55;
	setp.ne.s32 	%p6, %r38, 0;
	@%p6 bra 	$L__BB4_4;

$L__BB4_5:
	setp.eq.s32 	%p7, %r58, 0;
	@%p7 bra 	$L__BB4_8;

	shl.b32 	%r39, %r1, 1;
	or.b32  	%r40, %r39, 1;
	mad.lo.s32 	%r41, %r22, %r40, %r55;
	mul.wide.s32 	%rd28, %r41, 4;
	add.s64 	%rd41, %rd2, %rd28;
	shl.b32 	%r42, %r55, 1;
	or.b32  	%r43, %r42, 1;
	mad.lo.s32 	%r57, %r23, %r43, %r4;
	shl.b32 	%r14, %r23, 1;
	mul.lo.s32 	%r44, %r55, %r23;
	shl.b32 	%r45, %r44, 1;
	add.s32 	%r46, %r3, %r45;
	add.s32 	%r56, %r46, %r2;
	mul.lo.s32 	%r47, %r22, %r1;
	shl.b32 	%r48, %r47, 1;
	add.s32 	%r49, %r55, %r48;
	mul.wide.s32 	%rd29, %r49, 4;
	add.s64 	%rd40, %rd2, %rd29;

$L__BB4_7:
	.pragma "nounroll";
	mul.wide.s32 	%rd30, %r56, 4;
	add.s64 	%rd31, %rd1, %rd30;
	ld.global.f32 	%f44, [%rd31];
	ld.global.f32 	%f45, [%rd40];
	fma.rn.f32 	%f56, %f45, %f44, %f56;
	mul.wide.s32 	%rd32, %r57, 4;
	add.s64 	%rd33, %rd1, %rd32;
	ld.global.f32 	%f46, [%rd33];
	ld.global.f32 	%f47, [%rd41];
	fma.rn.f32 	%f57, %f47, %f46, %f57;
	add.s64 	%rd41, %rd41, 4;
	add.s32 	%r57, %r57, %r14;
	add.s32 	%r56, %r56, %r14;
	add.s64 	%rd40, %rd40, 4;
	add.s32 	%r58, %r58, -1;
	setp.ne.s32 	%p8, %r58, 0;
	@%p8 bra 	$L__BB4_7;

$L__BB4_8:
	cvta.to.global.u64 	%rd34, %rd14;
	shl.b32 	%r50, %r23, 1;
	mad.lo.s32 	%r51, %r50, %r1, %r4;
	mul.wide.s32 	%rd35, %r51, 4;
	add.s64 	%rd36, %rd34, %rd35;
	st.global.f32 	[%rd36], %f56;
	add.s32 	%r52, %r51, %r23;
	mul.wide.s32 	%rd37, %r52, 4;
	add.s64 	%rd38, %rd34, %rd37;
	st.global.f32 	[%rd38], %f57;

$L__BB4_9:
	ret;

}
	// .globl	surface_code_syndrome_kernel
.visible .entry surface_code_syndrome_kernel(
	.param .u64 surface_code_syndrome_kernel_param_0,
	.param .u64 surface_code_syndrome_kernel_param_1,
	.param .u64 surface_code_syndrome_kernel_param_2,
	.param .u64 surface_code_syndrome_kernel_param_3,
	.param .u32 surface_code_syndrome_kernel_param_4,
	.param .u32 surface_code_syndrome_kernel_param_5
)
{
	.reg .pred 	%p<14>;
	.reg .b16 	%rs<15>;
	.reg .f32 	%f<5>;
	.reg .b32 	%r<21>;
	.reg .b64 	%rd<22>;


	ld.param.u64 	%rd5, [surface_code_syndrome_kernel_param_0];
	ld.param.u64 	%rd2, [surface_code_syndrome_kernel_param_1];
	ld.param.u64 	%rd3, [surface_code_syndrome_kernel_param_2];
	ld.param.u64 	%rd4, [surface_code_syndrome_kernel_param_3];
	ld.param.u32 	%r6, [surface_code_syndrome_kernel_param_4];
	cvta.to.global.u64 	%rd1, %rd5;
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r8, %ctaid.x;
	mov.u32 	%r9, %tid.x;
	mad.lo.s32 	%r1, %r8, %r7, %r9;
	setp.ge.s32 	%p1, %r1, %r6;
	@%p1 bra 	$L__BB5_10;

	shl.b32 	%r10, %r1, 2;
	cvta.to.global.u64 	%rd6, %rd4;
	mul.wide.s32 	%rd7, %r10, 4;
	add.s64 	%rd8, %rd6, %rd7;
	ld.global.u32 	%r2, [%rd8+4];
	ld.global.u32 	%r3, [%rd8+8];
	ld.global.u32 	%r4, [%rd8+12];
	ld.global.u32 	%r5, [%rd8];
	setp.gt.s32 	%p2, %r5, 999;
	mov.u16 	%rs12, 0;
	@%p2 bra 	$L__BB5_3;

	shl.b32 	%r11, %r5, 1;
	mul.wide.s32 	%rd9, %r11, 4;
	add.s64 	%rd10, %rd1, %rd9;
	ld.global.f32 	%f1, [%rd10];
	setp.gt.f32 	%p3, %f1, 0f3F000000;
	selp.u16 	%rs12, 1, 0, %p3;

$L__BB5_3:
	setp.gt.s32 	%p4, %r2, 999;
	@%p4 bra 	$L__BB5_5;

	cvt.u32.u16 	%r12, %rs12;
	shl.b32 	%r13, %r2, 1;
	mul.wide.s32 	%rd11, %r13, 4;
	add.s64 	%rd12, %rd1, %rd11;
	ld.global.f32 	%f2, [%rd12];
	setp.gt.f32 	%p5, %f2, 0f3F000000;
	selp.u32 	%r14, 1, 0, %p5;
	setp.ne.s32 	%p6, %r12, %r14;
	selp.u16 	%rs12, 1, 0, %p6;

$L__BB5_5:
	setp.gt.s32 	%p7, %r3, 999;
	@%p7 bra 	$L__BB5_7;

	cvt.u32.u16 	%r15, %rs12;
	shl.b32 	%r16, %r3, 1;
	mul.wide.s32 	%rd13, %r16, 4;
	add.s64 	%rd14, %rd1, %rd13;
	ld.global.f32 	%f3, [%rd14];
	setp.gt.f32 	%p8, %f3, 0f3F000000;
	selp.u32 	%r17, 1, 0, %p8;
	setp.ne.s32 	%p9, %r15, %r17;
	selp.u16 	%rs12, 1, 0, %p9;

$L__BB5_7:
	setp.gt.s32 	%p10, %r4, 999;
	@%p10 bra 	$L__BB5_9;

	cvt.u32.u16 	%r18, %rs12;
	shl.b32 	%r19, %r4, 1;
	mul.wide.s32 	%rd15, %r19, 4;
	add.s64 	%rd16, %rd1, %rd15;
	ld.global.f32 	%f4, [%rd16];
	setp.gt.f32 	%p11, %f4, 0f3F000000;
	selp.u32 	%r20, 1, 0, %p11;
	setp.ne.s32 	%p12, %r18, %r20;
	selp.u16 	%rs12, 1, 0, %p12;

$L__BB5_9:
	cvt.s64.s32 	%rd17, %r1;
	cvta.to.global.u64 	%rd18, %rd2;
	add.s64 	%rd19, %rd18, %rd17;
	st.global.u8 	[%rd19], %rs12;
	setp.eq.s16 	%p13, %rs12, 0;
	selp.u16 	%rs10, 1, 0, %p13;
	cvta.to.global.u64 	%rd20, %rd3;
	add.s64 	%rd21, %rd20, %rd17;
	st.global.u8 	[%rd21], %rs10;

$L__BB5_10:
	ret;

}
	// .globl	syndrome_decoder_kernel
.visible .entry syndrome_decoder_kernel(
	.param .u64 syndrome_decoder_kernel_param_0,
	.param .u64 syndrome_decoder_kernel_param_1,
	.param .u32 syndrome_decoder_kernel_param_2
)
{
	.reg .pred 	%p<4>;
	.reg .b16 	%rs<3>;
	.reg .b32 	%r<11>;
	.reg .b64 	%rd<9>;


	ld.param.u64 	%rd3, [syndrome_decoder_kernel_param_0];
	ld.param.u64 	%rd4, [syndrome_decoder_kernel_param_1];
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %ctaid.x;
	mov.u32 	%r4, %tid.x;
	mad.lo.s32 	%r1, %r3, %r2, %r4;
	ld.param.u32 	%r5, [syndrome_decoder_kernel_param_2];
	shr.u32 	%r6, %r5, 31;
	add.s32 	%r7, %r5, %r6;
	shr.s32 	%r8, %r7, 1;
	setp.ge.s32 	%p1, %r1, %r8;
	@%p1 bra 	$L__BB6_4;

	shl.b32 	%r9, %r1, 1;
	cvt.s64.s32 	%rd1, %r9;
	cvta.to.global.u64 	%rd5, %rd3;
	add.s64 	%rd2, %rd5, %rd1;
	ld.global.u8 	%rs1, [%rd2];
	setp.eq.s16 	%p2, %rs1, 0;
	@%p2 bra 	$L__BB6_4;

	ld.global.u8 	%rs2, [%rd2+1];
	setp.eq.s16 	%p3, %rs2, 0;
	@%p3 bra 	$L__BB6_4;

	cvta.to.global.u64 	%rd6, %rd4;
	shl.b64 	%rd7, %rd1, 2;
	add.s64 	%rd8, %rd6, %rd7;
	mov.u32 	%r10, 1;
	st.global.u32 	[%rd8], %r10;
	st.global.u32 	[%rd8+4], %r10;

$L__BB6_4:
	ret;

}
	// .globl	quantum_hebbian_kernel
.visible .entry quantum_hebbian_kernel(
	.param .u64 quantum_hebbian_kernel_param_0,
	.param .u64 quantum_hebbian_kernel_param_1,
	.param .u64 quantum_hebbian_kernel_param_2,
	.param .u32 quantum_hebbian_kernel_param_3,
	.param .f32 quantum_hebbian_kernel_param_4,
	.param .f32 quantum_hebbian_kernel_param_5
)
{
	.reg .pred 	%p<6>;
	.reg .f32 	%f<13>;
	.reg .b32 	%r<11>;
	.reg .b64 	%rd<14>;


	ld.param.u64 	%rd1, [quantum_hebbian_kernel_param_0];
	ld.param.u64 	%rd2, [quantum_hebbian_kernel_param_1];
	ld.param.u64 	%rd3, [quantum_hebbian_kernel_param_2];
	ld.param.u32 	%r3, [quantum_hebbian_kernel_param_3];
	ld.param.f32 	%f1, [quantum_hebbian_kernel_param_4];
	ld.param.f32 	%f2, [quantum_hebbian_kernel_param_5];
	mov.u32 	%r4, %ntid.x;
	mov.u32 	%r5, %ctaid.x;
	mov.u32 	%r6, %tid.x;
	mad.lo.s32 	%r1, %r5, %r4, %r6;
	mov.u32 	%r7, %ntid.y;
	mov.u32 	%r8, %ctaid.y;
	mov.u32 	%r9, %tid.y;
	mad.lo.s32 	%r2, %r8, %r7, %r9;
	setp.ge.s32 	%p1, %r1, %r3;
	setp.ge.s32 	%p2, %r2, %r3;
	or.pred  	%p3, %p1, %p2;
	setp.eq.s32 	%p4, %r1, %r2;
	or.pred  	%p5, %p4, %p3;
	@%p5 bra 	$L__BB7_2;

	cvta.to.global.u64 	%rd4, %rd1;
	cvta.to.global.u64 	%rd5, %rd2;
	mul.wide.s32 	%rd6, %r1, 4;
	add.s64 	%rd7, %rd4, %rd6;
	ld.global.f32 	%f3, [%rd7];
	add.f32 	%f4, %f3, 0f428C0000;
	div.rn.f32 	%f5, %f4, 0f42C80000;
	mul.wide.s32 	%rd8, %r2, 4;
	add.s64 	%rd9, %rd4, %rd8;
	ld.global.f32 	%f6, [%rd9];
	add.f32 	%f7, %f6, 0f428C0000;
	div.rn.f32 	%f8, %f7, 0f42C80000;
	mul.f32 	%f9, %f5, %f8;
	mad.lo.s32 	%r10, %r1, %r3, %r2;
	mul.wide.s32 	%rd10, %r10, 4;
	add.s64 	%rd11, %rd5, %rd10;
	ld.global.f32 	%f10, [%rd11];
	fma.rn.f32 	%f11, %f10, %f2, %f9;
	mul.f32 	%f12, %f11, %f1;
	cvta.to.global.u64 	%rd12, %rd3;
	add.s64 	%rd13, %rd12, %rd10;
	st.global.f32 	[%rd13], %f12;

$L__BB7_2:
	ret;

}
	// .globl	toric_code_anyon_kernel
.visible .entry toric_code_anyon_kernel(
	.param .u64 toric_code_anyon_kernel_param_0,
	.param .u64 toric_code_anyon_kernel_param_1,
	.param .u64 toric_code_anyon_kernel_param_2,
	.param .u32 toric_code_anyon_kernel_param_3
)
{
	.reg .pred 	%p<6>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<14>;
	.reg .b64 	%rd<12>;


	ld.param.u64 	%rd1, [toric_code_anyon_kernel_param_0];
	ld.param.u64 	%rd2, [toric_code_anyon_kernel_param_1];
	ld.param.u64 	%rd3, [toric_code_anyon_kernel_param_2];
	ld.param.u32 	%r3, [toric_code_anyon_kernel_param_3];
	mov.u32 	%r4, %ntid.x;
	mov.u32 	%r5, %ctaid.x;
	mov.u32 	%r6, %tid.x;
	mad.lo.s32 	%r1, %r5, %r4, %r6;
	mov.u32 	%r7, %ntid.y;
	mov.u32 	%r8, %ctaid.y;
	mov.u32 	%r9, %tid.y;
	mad.lo.s32 	%r2, %r8, %r7, %r9;
	setp.ge.s32 	%p1, %r1, %r3;
	setp.ge.s32 	%p2, %r2, %r3;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	$L__BB8_2;

	cvta.to.global.u64 	%rd4, %rd2;
	mad.lo.s32 	%r10, %r1, %r3, %r2;
	shl.b32 	%r11, %r10, 2;
	cvta.to.global.u64 	%rd5, %rd1;
	mul.wide.s32 	%rd6, %r11, 4;
	add.s64 	%rd7, %rd5, %rd6;
	ld.global.f32 	%f1, [%rd7];
	setp.lt.f32 	%p4, %f1, 0f3F000000;
	selp.u32 	%r12, 1, 0, %p4;
	mul.wide.s32 	%rd8, %r10, 4;
	add.s64 	%rd9, %rd4, %rd8;
	st.global.u32 	[%rd9], %r12;
	ld.global.f32 	%f2, [%rd7+4];
	setp.lt.f32 	%p5, %f2, 0f3F000000;
	selp.u32 	%r13, 1, 0, %p5;
	cvta.to.global.u64 	%rd10, %rd3;
	add.s64 	%rd11, %rd10, %rd8;
	st.global.u32 	[%rd11], %r13;

$L__BB8_2:
	ret;

}
	// .globl	hadamard_transform_kernel
.visible .entry hadamard_transform_kernel(
	.param .u64 hadamard_transform_kernel_param_0,
	.param .u64 hadamard_transform_kernel_param_1,
	.param .u32 hadamard_transform_kernel_param_2
)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<7>;
	.reg .b32 	%r<8>;
	.reg .b64 	%rd<8>;


	ld.param.u64 	%rd1, [hadamard_transform_kernel_param_0];
	ld.param.u64 	%rd2, [hadamard_transform_kernel_param_1];
	ld.param.u32 	%r2, [hadamard_transform_kernel_param_2];
	mov.u32 	%r3, %ctaid.x;
	mov.u32 	%r4, %ntid.x;
	mov.u32 	%r5, %tid.x;
	mad.lo.s32 	%r1, %r3, %r4, %r5;
	mov.u32 	%r6, 1;
	shl.b32 	%r7, %r6, %r2;
	setp.ge.s32 	%p1, %r1, %r7;
	@%p1 bra 	$L__BB9_2;

	cvta.to.global.u64 	%rd3, %rd1;
	mul.wide.s32 	%rd4, %r1, 4;
	add.s64 	%rd5, %rd3, %rd4;
	cvta.to.global.u64 	%rd6, %rd2;
	add.s64 	%rd7, %rd6, %rd4;
	ld.global.f32 	%f1, [%rd7];
	ld.global.f32 	%f2, [%rd5];
	mov.f32 	%f3, 0f40000000;
	rsqrt.approx.f32 	%f4, %f3;
	mul.f32 	%f5, %f4, %f2;
	st.global.f32 	[%rd5], %f5;
	mul.f32 	%f6, %f4, %f1;
	st.global.f32 	[%rd7], %f6;

$L__BB9_2:
	ret;

}
	// .globl	measurement_feedback_kernel
.visible .entry measurement_feedback_kernel(
	.param .u64 measurement_feedback_kernel_param_0,
	.param .u64 measurement_feedback_kernel_param_1,
	.param .u32 measurement_feedback_kernel_param_2,
	.param .f32 measurement_feedback_kernel_param_3
)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<10>;
	.reg .b32 	%r<6>;
	.reg .b64 	%rd<8>;


	ld.param.u64 	%rd1, [measurement_feedback_kernel_param_0];
	ld.param.u64 	%rd2, [measurement_feedback_kernel_param_1];
	ld.param.u32 	%r2, [measurement_feedback_kernel_param_2];
	ld.param.f32 	%f1, [measurement_feedback_kernel_param_3];
	mov.u32 	%r3, %ctaid.x;
	mov.u32 	%r4, %ntid.x;
	mov.u32 	%r5, %tid.x;
	mad.lo.s32 	%r1, %r3, %r4, %r5;
	setp.ge.s32 	%p1, %r1, %r2;
	@%p1 bra 	$L__BB10_2;

	cvta.to.global.u64 	%rd3, %rd1;
	cvta.to.global.u64 	%rd4, %rd2;
	mul.wide.s32 	%rd5, %r1, 4;
	add.s64 	%rd6, %rd4, %rd5;
	ld.global.f32 	%f2, [%rd6];
	fma.rn.f32 	%f3, %f2, 0f40000000, 0fBF800000;
	add.s64 	%rd7, %rd3, %rd5;
	ld.global.f32 	%f4, [%rd7];
	fma.rn.f32 	%f5, %f3, %f1, %f4;
	mov.f32 	%f6, 0fC2A00000;
	max.f32 	%f7, %f5, %f6;
	mov.f32 	%f8, 0f41F00000;
	min.f32 	%f9, %f7, %f8;
	st.global.f32 	[%rd7], %f9;

$L__BB10_2:
	ret;

}
	// .globl	tomography_reconstruction_kernel
.visible .entry tomography_reconstruction_kernel(
	.param .u64 tomography_reconstruction_kernel_param_0,
	.param .u64 tomography_reconstruction_kernel_param_1,
	.param .u32 tomography_reconstruction_kernel_param_2
)
{
	.reg .pred 	%p<16>;
	.reg .f32 	%f<10>;
	.reg .b32 	%r<13>;
	.reg .b64 	%rd<5>;


	ld.param.u64 	%rd2, [tomography_reconstruction_kernel_param_0];
	ld.param.u64 	%rd3, [tomography_reconstruction_kernel_param_1];
	ld.param.u32 	%r3, [tomography_reconstruction_kernel_param_2];
	cvta.to.global.u64 	%rd1, %rd3;
	mov.u32 	%r4, %ntid.x;
	mov.u32 	%r5, %ctaid.x;
	mov.u32 	%r6, %tid.x;
	mad.lo.s32 	%r1, %r5, %r4, %r6;
	mov.u32 	%r7, %ntid.y;
	mov.u32 	%r8, %ctaid.y;
	mov.u32 	%r9, %tid.y;
	mad.lo.s32 	%r2, %r8, %r7, %r9;
	mov.u32 	%r10, 1;
	shl.b32 	%r11, %r10, %r3;
	setp.ge.s32 	%p1, %r1, %r11;
	setp.ge.s32 	%p2, %r2, %r11;
	or.pred  	%p3, %p1, %p2;
	setp.ne.s32 	%p4, %r3, 1;
	or.pred  	%p5, %p4, %p3;
	@%p5 bra 	$L__BB11_9;

	cvta.to.global.u64 	%rd4, %rd2;
	ld.global.f32 	%f1, [%rd4];
	ld.global.f32 	%f2, [%rd4+8];
	or.b32  	%r12, %r1, %r2;
	setp.ne.s32 	%p6, %r12, 0;
	@%p6 bra 	$L__BB11_3;

	add.f32 	%f3, %f2, 0f3F800000;
	mul.f32 	%f4, %f3, 0f3F000000;
	st.global.f32 	[%rd1], %f4;

$L__BB11_3:
	setp.ne.s32 	%p7, %r1, 0;
	setp.ne.s32 	%p8, %r2, 1;
	or.pred  	%p9, %p7, %p8;
	@%p9 bra 	$L__BB11_5;

	mul.f32 	%f5, %f1, 0f3F000000;
	st.global.f32 	[%rd1+4], %f5;

$L__BB11_5:
	setp.ne.s32 	%p10, %r1, 1;
	setp.ne.s32 	%p11, %r2, 0;
	or.pred  	%p12, %p10, %p11;
	@%p12 bra 	$L__BB11_7;

	mul.f32 	%f6, %f1, 0f3F000000;
	st.global.f32 	[%rd1+8], %f6;

$L__BB11_7:
	or.pred  	%p15, %p10, %p8;
	@%p15 bra 	$L__BB11_9;

	mov.f32 	%f7, 0f3F800000;
	sub.f32 	%f8, %f7, %f2;
	mul.f32 	%f9, %f8, 0f3F000000;
	st.global.f32 	[%rd1+12], %f9;

$L__BB11_9:
	ret;

}

