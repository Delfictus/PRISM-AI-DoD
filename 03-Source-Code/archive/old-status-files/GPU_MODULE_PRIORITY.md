# ðŸŽ¯ GPU Module Priority List
## Ranked by Impact & Implementation Complexity

---

## ðŸ”´ CRITICAL PRIORITY (Do First - High Impact, Clear Path)

### 1. **PWSA Active Inference Classifier** â­â­â­â­â­
**File**: `src/pwsa/active_inference_classifier.rs`
- **Current**: CPU-only Linear layers and softmax
- **GPU Ops Needed**: Matrix multiply, softmax, cross-entropy
- **Expected Speedup**: 20-30x
- **Complexity**: Low (well-defined operations)
- **Why First**: Self-contained, immediate benefit, clear operations

### 2. **Transfer Entropy Calculator** â­â­â­â­â­
**File**: `src/cma/transfer_entropy_gpu.rs`
- **Current**: Sequential k-NN and entropy calculations
- **GPU Ops Needed**: Parallel k-NN, histogram, mutual information
- **Expected Speedup**: 50-100x
- **Complexity**: Medium (parallel algorithms needed)
- **Why Priority**: Heavy compute, used frequently

### 3. **GPU Launcher Core** â­â­â­â­â­
**File**: `src/gpu_launcher.rs`
- **Current**: Placeholder implementations
- **GPU Ops Needed**: Memory management, kernel dispatch
- **Expected Speedup**: N/A (infrastructure)
- **Complexity**: Low (fix existing structure)
- **Why Priority**: Required by all other modules

---

## ðŸŸ¡ HIGH PRIORITY (Significant Performance Gains)

### 4. **Neural Quantum State VMC** â­â­â­â­
**File**: `src/cma/neural/neural_quantum.rs`
- **Current**: CPU Monte Carlo sampling
- **GPU Ops Needed**: Parallel sampling, ResNet forward, Metropolis
- **Expected Speedup**: 50-200x
- **Complexity**: High (stochastic algorithms)
- **Why High**: Massive parallelism opportunity

### 5. **Active Inference Policy Evaluation** â­â­â­â­
**File**: `src/active_inference/gpu_policy_eval.rs`
- **Current**: Sequential free energy computation
- **GPU Ops Needed**: Belief propagation, expectation
- **Expected Speedup**: 30-50x
- **Complexity**: Medium
- **Why High**: Core to decision making

### 6. **Thermodynamic Evolution** â­â­â­â­
**File**: `src/statistical_mechanics/gpu_bindings.rs`
- **Current**: CPU physics simulation
- **GPU Ops Needed**: Hamiltonian evolution, phase space
- **Expected Speedup**: 40-60x
- **Complexity**: Medium
- **Why High**: Time-stepping benefits from GPU

---

## ðŸŸ¢ MEDIUM PRIORITY (Good Gains, More Complex)

### 7. **Graph Coloring** â­â­â­
**File**: `src/prct-core/coloring.rs`
- **Current**: Sequential greedy algorithm
- **GPU Ops Needed**: Parallel color assignment
- **Expected Speedup**: 10-20x
- **Complexity**: High (irregular memory)

### 8. **TSP Solver** â­â­â­
**File**: `src/prct-core/tsp_gpu.rs`
- **Current**: CPU branch-and-bound
- **GPU Ops Needed**: Parallel neighborhood search
- **Expected Speedup**: 15-25x
- **Complexity**: High (complex algorithms)

### 9. **E3-Equivariant GNN** â­â­â­
**File**: `src/cma/neural/gnn_integration.rs`
- **Current**: Stub implementation
- **GPU Ops Needed**: Message passing, aggregation
- **Expected Speedup**: 20-40x
- **Complexity**: High (graph operations)

### 10. **Consistency Diffusion** â­â­â­
**File**: `src/cma/neural/diffusion.rs`
- **Current**: Stub implementation
- **GPU Ops Needed**: Noise generation, U-Net
- **Expected Speedup**: 30-50x
- **Complexity**: High (needs full implementation)

---

## ðŸ”µ LOWER PRIORITY (Optimize Later)

### 11. **QUBO Optimization** â­â­
**File**: `src/prct-core/qubo.rs`
- **GPU Ops**: Quadratic form evaluation
- **Expected Speedup**: 10-15x

### 12. **Simulated Annealing** â­â­
**File**: `src/prct-core/simulated_annealing.rs`
- **GPU Ops**: Parallel temperature chains
- **Expected Speedup**: 5-10x

### 13. **PAC-Bayes Bounds** â­â­
**File**: `src/cma/pac_bayes.rs`
- **GPU Ops**: Statistical computations
- **Expected Speedup**: 5-8x

### 14. **Conformal Prediction** â­â­
**File**: `src/cma/conformal_prediction.rs`
- **GPU Ops**: Set operations
- **Expected Speedup**: 3-5x

---

## ðŸ“Š Module Dependency Graph

```
gpu_launcher.rs (Infrastructure)
    â”œâ”€â”€ memory_manager.rs (NEW - Create First)
    â””â”€â”€ kernel_launcher.rs (NEW - Create Second)
            â”‚
            â”œâ”€â”€ active_inference_classifier.rs (Port First)
            â”œâ”€â”€ transfer_entropy_gpu.rs (Port Second)
            â”œâ”€â”€ neural_quantum.rs (Port Third)
            â””â”€â”€ gpu_policy_eval.rs (Port Fourth)
```

---

## âš¡ Quick Win Implementations

### WEEK 1 TARGETS (Maximum Impact)
1. **Monday**: GPU memory manager + kernel infrastructure
2. **Tuesday**: PWSA classifier GPU acceleration
3. **Wednesday**: Transfer entropy GPU kernel
4. **Thursday**: Test, benchmark, optimize
5. **Friday**: Documentation + plan Week 2

### Expected Week 1 Outcomes:
- âœ… 2 modules fully GPU-accelerated
- âœ… 20-50x speedup demonstrated
- âœ… Infrastructure ready for remaining modules
- âœ… Benchmarks proving GPU advantage

---

## ðŸ”§ Files That Need Creation

### New Infrastructure Files:
```
src/gpu/
â”œâ”€â”€ memory_manager.rs      # GPU memory pool
â”œâ”€â”€ kernel_launcher.rs      # Kernel dispatch
â”œâ”€â”€ tensor_ops.rs          # GPU tensor operations
â””â”€â”€ layers/
    â”œâ”€â”€ linear.rs          # GPU Linear layer
    â”œâ”€â”€ activation.rs      # GPU activations
    â””â”€â”€ normalization.rs   # GPU LayerNorm, etc.

src/kernels/cuda/
â”œâ”€â”€ matrix_ops.cu          # GEMM, transpose
â”œâ”€â”€ reduction_ops.cu       # Sum, mean, max
â”œâ”€â”€ activation_ops.cu      # ReLU, sigmoid, softmax
â”œâ”€â”€ entropy_ops.cu         # Transfer entropy
â””â”€â”€ graph_ops.cu          # Graph algorithms
```

---

## ðŸ“ˆ Performance Impact Analysis

| Module | Current Time | GPU Time | Users Impacted | Business Value |
|--------|-------------|----------|----------------|----------------|
| PWSA Classifier | 100ms | 5ms | All inference | â­â­â­â­â­ |
| Transfer Entropy | 500ms | 10ms | Causal analysis | â­â­â­â­â­ |
| Neural Quantum | 1000ms | 20ms | Optimization | â­â­â­â­ |
| Policy Eval | 200ms | 10ms | Decision making | â­â­â­â­ |
| Graph Coloring | 50ms | 5ms | PRCT core | â­â­â­ |

---

## âœ… Success Criteria

A module is considered "GPU-accelerated" when:
1. âœ… All compute-intensive operations run on GPU
2. âœ… Achieves >10x speedup over CPU
3. âœ… Passes all existing tests
4. âœ… Has fallback to CPU if GPU unavailable
5. âœ… Memory usage is optimized
6. âœ… No memory leaks verified

---

## ðŸš€ RECOMMENDED FIRST ACTION

**START WITH**: `src/pwsa/active_inference_classifier.rs`

**Step 1**: Create `src/gpu/layers/linear.rs`
```rust
// Implement GPU-accelerated Linear layer
// This will be reusable across multiple modules
```

**Step 2**: Replace in classifier:
```rust
// Old:
let fc1 = Linear::new(100, 64);

// New:
let fc1 = GpuLinear::new(ctx.clone(), 100, 64)?;
```

**Step 3**: Benchmark:
```bash
cargo bench --features cuda active_inference
```

**Expected Result**: 20-30x speedup on forward pass

---

*This priority list provides clear guidance on which modules to GPU-accelerate first for maximum impact.*