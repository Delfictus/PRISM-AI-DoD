# ServiceMonitor for Prometheus Operator
# Automatically configures Prometheus to scrape metrics

apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: prism-api-monitor
  namespace: prism-ai
  labels:
    app: prism-api-server
    prometheus: kube-prometheus
spec:
  selector:
    matchLabels:
      app: prism-api-server
  endpoints:
  - port: http
    path: /metrics
    interval: 30s
    scrapeTimeout: 10s
    scheme: http

---
# PrometheusRule for alerting
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: prism-api-alerts
  namespace: prism-ai
  labels:
    prometheus: kube-prometheus
    role: alert-rules
spec:
  groups:
  - name: prism-api
    interval: 30s
    rules:
    # High error rate
    - alert: HighErrorRate
      expr: |
        sum(rate(http_requests_total{status=~"5.."}[5m])) /
        sum(rate(http_requests_total[5m])) > 0.05
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "High error rate detected"
        description: "Error rate is above 5% for 5 minutes"

    # High latency
    - alert: HighLatency
      expr: |
        histogram_quantile(0.95,
          rate(http_request_duration_seconds_bucket[5m])
        ) > 1.0
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "High API latency"
        description: "P95 latency is above 1 second"

    # Low availability
    - alert: LowAvailability
      expr: |
        sum(up{job="prism-api-server"}) /
        count(up{job="prism-api-server"}) < 0.8
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: "Low API availability"
        description: "Less than 80% of pods are healthy"

    # High memory usage
    - alert: HighMemoryUsage
      expr: |
        container_memory_usage_bytes{pod=~"prism-api-server-.*"} /
        container_spec_memory_limit_bytes{pod=~"prism-api-server-.*"} > 0.9
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "High memory usage"
        description: "Memory usage is above 90%"

    # GPU not available
    - alert: GPUUnavailable
      expr: |
        nvidia_gpu_num_devices == 0
      for: 1m
      labels:
        severity: critical
      annotations:
        summary: "GPU not detected"
        description: "No GPU devices found in pod"
